{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d9ae70-0700-444d-b057-7f474dbb0876",
   "metadata": {},
   "source": [
    "# Build, Train & Score Model with PyTorch\n",
    "\n",
    "### Introduction: Rahul Nair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41264b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seaborn\n",
    "#%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef53d2c-5c27-4bc0-80e5-e622ea6f3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"ipex version: {ipex.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed: int = 4242):\n",
    "    \"\"\"set all random seeds using `seed`\"\"\"\n",
    "    print(f\"seed set to: {seed}\")\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def set_env_vars() -> int:\n",
    "    \"\"\"set openMP and torch params\"\"\"\n",
    "    num_physical_cores = psutil.cpu_count(logical=False)\n",
    "    print(f\"setting omp num threads: {num_physical_cores}\")\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(num_physical_cores)\n",
    "    os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,compact,1,0\"\n",
    "    os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "    return num_physical_cores\n",
    "\n",
    "\n",
    "seed_everything(9342)\n",
    "num_physical_cores = set_env_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, validation & test dataset transforms, test and validation transforms are the same\n",
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "img_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomApply(\n",
    "                [transforms.GaussianBlur(kernel_size=(1, 3), sigma=(1, 3))], p=0.2\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(180),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*imagenet_stats),\n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa503e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for Training and Validation\n",
    "num_physical_cores = psutil.cpu_count(logical=False)\n",
    "data_dir = pathlib.Path(\"./data/ThreeClassManualRemove0s/\")\n",
    "TRAIN_DIR = data_dir / \"train\"\n",
    "VALID_DIR = data_dir / \"val\"\n",
    "\n",
    "# no augmentation for test and validation data\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=img_transforms[\"train\"])\n",
    "test_data = datasets.ImageFolder(  \n",
    "    TRAIN_DIR, transform=img_transforms[\"valid\"]\n",
    ")\n",
    "valid_data = datasets.ImageFolder(VALID_DIR, transform=img_transforms[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distribution(dataset=train_data, path: str = TRAIN_DIR) -> dict:\n",
    "    \"\"\"return dict of data distribtion of each class.\"\"\"\n",
    "    cls_count = dict.fromkeys(dataset.class_to_idx, 0)\n",
    "    for cls in cls_count.keys():\n",
    "        cls_count[cls] = len(fnmatch.filter(os.listdir(f\"{path}/{cls}\"), \"*.png\"))\n",
    "    return cls_count\n",
    "\n",
    "\n",
    "def plot_data_distribution(data_dist: dict, title: str = \"\"):\n",
    "    \"\"\"plot data distribution\"\"\"\n",
    "    cls, count = list(data_dist.keys()), list(data_dist.values())\n",
    "    p = sns.barplot(x=cls, y=count)\n",
    "    p.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cda558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dist = data_distribution(train_data, path=TRAIN_DIR)\n",
    "plot_data_distribution(train_data_dist, \"train_data_dist\")\n",
    "print(f\"train data dist: {train_data_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_dist = data_distribution(valid_data, path=VALID_DIR)\n",
    "plot_data_distribution(valid_data_dist, \"valid_data_dist\")\n",
    "print(f\"valid data dist: {valid_data_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcab709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test dataset from train_data\n",
    "dataset_len = len(train_data.targets)\n",
    "data_idx = [x for x in range(dataset_len)]\n",
    "train_idx, test_idx = train_test_split(\n",
    "    data_idx, test_size=0.3, stratify=train_data.targets, shuffle=True\n",
    ")\n",
    "train_data = torch.utils.data.Subset(train_data, train_idx)\n",
    "test_data = torch.utils.data.Subset(test_data, test_idx)\n",
    "print(f\" train, valid, test sizes: {len(train_data), len(test_data), len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create data loaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size)\n",
    "print(f\"batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _denormalize(images, imagenet_stats):\n",
    "    \"\"\"de normalize dataset using imagenet std and mean to show images\"\"\"\n",
    "    mean = torch.tensor(imagenet_stats[0]).reshape(1, 3, 1, 1)\n",
    "    std = torch.tensor(imagenet_stats[1]).reshape(1, 3, 1, 1)\n",
    "    return images * std + mean\n",
    "\n",
    "\n",
    "def show_data(dataloader, imagenet_stats=imagenet_stats, num_data=4, figsize=(10,6)):\n",
    "    \"\"\"show `num_data` of images and labels from dataloader.\"\"\"\n",
    "    batch = next(iter(dataloader))  # batch of with images, batch of labels\n",
    "    imgs, labels = (\n",
    "        batch[0][:num_data],\n",
    "        batch[1][:num_data].tolist(),\n",
    "    )  # get num_data of images, labels\n",
    "    plt.style.use(\"dark_background\")\n",
    "    _, axes = plt.subplots(1, num_data, figsize=figsize)\n",
    "    for n in range(num_data):\n",
    "        axes[n].set_title(labels[n])\n",
    "        imgs[n] = _denormalize(imgs[n], imagenet_stats)\n",
    "        axes[n].imshow(torch.clamp(imgs[n], 0, 1).permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training data\")\n",
    "show_data(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89065081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test data\")\n",
    "show_data(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation data\")\n",
    "show_data(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinosourBoneFinder(nn.Module):\n",
    "    \"\"\"\n",
    "    A model to classify aerial images that could potential have Jurassic fossils.\n",
    "    We are using a backbone pretrained resnet model and images given to model are\n",
    "    classified into one of 3 classes.\n",
    "    0 - no bone\n",
    "    1 - bone possible\n",
    "    2 - bone likely\n",
    "    \n",
    "    We currently use the resnet18 model as a backbone\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone=18, simple=False):\n",
    "        super(DinosourBoneFinder, self).__init__()\n",
    "        backbones = {\n",
    "            18: models.resnet18,\n",
    "            34: models.resnet34,\n",
    "            50: models.resnet50,\n",
    "            101: models.resnet101,\n",
    "        }\n",
    "        self.network = backbones[backbone](pretrained=True)\n",
    "        for m, p in zip(self.network.modules(), self.network.parameters()):\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                p.requires_grad = False\n",
    "        if simple:\n",
    "            self.network.fc = nn.Linear(self.network.fc.in_features, 3)\n",
    "        else:\n",
    "            self.network.fc = nn.Sequential(\n",
    "                nn.Linear(self.network.fc.in_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.6),\n",
    "                nn.Linear(256, 3),\n",
    "            )\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        return self.network(x_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"class that holds logic for calculating accuracy and printing it\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.acc = {\"train\": [], \"val\": []}\n",
    "        self.loss = {\"train\": [], \"val\": []}\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def accuracy(yhat, labels, debug):\n",
    "        \"\"\"accuracy of a batch\"\"\"\n",
    "        yhat = torch.log_softmax(yhat, dim=1)  # softmax of logit output\n",
    "        yhat = yhat.max(1)[1]  # get index of max values\n",
    "        if debug:\n",
    "            print(f\"outputs: {yhat}\")\n",
    "            print(f\"labels: {labels}\")\n",
    "        acc = yhat.eq(labels).sum() / len(yhat)\n",
    "        return acc\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"loss:\\n training set  : {self.loss['train'][-1]:.4}\\n validation set: {self.loss['val'][-1]:.4}\\n\"\n",
    "            f\"accuracy:\\n training set  : {self.acc['train'][-1]:.4}\\n validation set: {self.acc['val'][-1]:.4} \"\n",
    "        )\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"plot loss and acc curves\"\"\"\n",
    "        train_acc = [x * 100 for x in self.acc[\"train\"]]\n",
    "        val_acc = [x * 100 for x in self.acc[\"val\"]]\n",
    "        _, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 2.5))\n",
    "        ax[0].plot(self.loss[\"train\"], \"-o\")\n",
    "        ax[0].plot(self.loss[\"val\"], \"-o\")\n",
    "        ax[0].set_ylabel(\"loss\")\n",
    "        ax[0].set_title(f\"Train vs validation loss\")\n",
    "        ax[1].plot(train_acc, \"-o\")\n",
    "        ax[1].plot(val_acc, \"-o\")\n",
    "        ax[1].set_ylabel(\"accuracy (%)\")\n",
    "        ax[1].set_title(\"Training vs validation acc\")\n",
    "        for x in ax:\n",
    "            x.yaxis.grid(True)\n",
    "            x.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "            x.legend([\"train\", \"validation\"])\n",
    "            x.set_xlabel(\"epoch\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Trainer class that takes care of training and validation passes.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        device=\"cpu\",\n",
    "        optimizer=torch.optim.SGD,\n",
    "        epochs=10,\n",
    "        lr=0.05,\n",
    "        ipx=False,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.ipx = ipx\n",
    "        self.epochs = epochs\n",
    "        self.metrics = Metrics()\n",
    "        self.lr = lr\n",
    "        if isinstance(optimizer, torch.optim.Adam):\n",
    "            self.lr = 2e-3\n",
    "        self.optimizer = optimizer(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def forward_pass(self, inputs, labels, debug=False):\n",
    "        \"\"\"Perform forward pass of models with `inputs`,\n",
    "        calculate loss and accuracy and return it.\n",
    "        \"\"\"\n",
    "        outputs = self.model(inputs)  # forward pass model\n",
    "        loss = self.loss_fn(outputs, labels)  # calculate loss\n",
    "        acc = self.metrics.accuracy(outputs, labels, debug=debug)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_one_batch(self, max_epoch=100):\n",
    "        \"\"\"Train the model using just one batch for max_epoch.\n",
    "        use this function to debug the training loop\"\"\"\n",
    "        self.model.train()\n",
    "        inputs, labels = next(iter(self.train_dataloader))\n",
    "        for epoch in range(max_epoch):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()  # zero gradients\n",
    "            loss, _ = self.forward_pass(inputs, labels, debug=True)\n",
    "            loss.backward()  # calculate gradients\n",
    "            self.optimizer.step()  # update params\n",
    "            print(\n",
    "                f\"[Epoch: {epoch+1}]\\\n",
    "                    \\n loss: {loss.item()/len(self.train_dataloader):.4f}\"\n",
    "            )\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training loop, return epoch loss and accuracy.\"\"\"\n",
    "        self.model.train()\n",
    "        t_epoch_loss, t_epoch_acc = 0.0, 0.0\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=\"tr loop\"):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            if self.ipx:\n",
    "                inputs = inputs.to(memory_format=torch.channels_last)\n",
    "            self.optimizer.zero_grad()  # zero gradients\n",
    "            loss, acc = self.forward_pass(inputs, labels)  # forward pass\n",
    "            loss.backward()  # backward\n",
    "            self.optimizer.step()  # update gradients\n",
    "            t_epoch_loss += loss.item()\n",
    "            t_epoch_acc += acc.item()\n",
    "        return (t_epoch_loss, t_epoch_acc)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        \"\"\"Validation loop, return validation epoch loss and accuracy.\"\"\"\n",
    "        self.model.eval()\n",
    "        v_epoch_loss, v_epoch_acc = 0.0, 0.0\n",
    "        for inputs, labels in tqdm(self.valid_dataloader, desc=\"ev loop\"):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            loss, acc = self.forward_pass(inputs, labels)\n",
    "            v_epoch_loss += loss.item()\n",
    "            v_epoch_acc += acc.item()\n",
    "        return (v_epoch_loss, v_epoch_acc)\n",
    "\n",
    "    def _to_ipx(self):\n",
    "        \"\"\"convert model memory format to channels_last to IPEX format.\"\"\"\n",
    "        self.model.train()\n",
    "        self.model = self.model.to(memory_format=torch.channels_last)\n",
    "        self.model, self.optimizer = ipex.optimize(\n",
    "            self.model, optimizer=self.optimizer, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def fine_tune(self, train_dataloader, valid_dataloader, debug=False):\n",
    "        \"\"\"Fine tune `self.model` using training set and measure perf using\n",
    "        training and validation set.\n",
    "\n",
    "        `debug`: if True, will run train_one_batch function with one batch\n",
    "        of train_dataloader to see if we can overfit the model, used to debug\n",
    "        the training loop.\n",
    "\n",
    "        `train_dataloader`: training set\n",
    "        `valid_dataloader`: validation set\n",
    "        \"\"\"\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        if debug:\n",
    "            self.train_one_batch()\n",
    "        else:\n",
    "            time_per_epoch = []\n",
    "            if self.ipx:\n",
    "                self._to_ipx()\n",
    "            print(f\"fine tuning model for max epochs: {self.epochs}\")\n",
    "            for epoch in range(self.epochs):\n",
    "                print(f\"Epoch: [{epoch+1}]\")\n",
    "                st_time = time.perf_counter()\n",
    "                t_epoch_loss, t_epoch_acc = self.train()\n",
    "                fn_time = time.perf_counter()\n",
    "                time_per_epoch.append(fn_time - st_time)\n",
    "                v_epoch_loss, v_epoch_acc = self.validate()\n",
    "                self.metrics.loss[\"train\"].append(t_epoch_loss / len(train_dataloader))\n",
    "                self.metrics.loss[\"val\"].append(v_epoch_loss / len(valid_dataloader))\n",
    "                self.metrics.acc[\"train\"].append(t_epoch_acc / len(train_dataloader))\n",
    "                self.metrics.acc[\"val\"].append(v_epoch_acc / len(valid_dataloader))\n",
    "                print(self.metrics)\n",
    "            return time_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a30e4e-1e97-4336-8162-6269d28ffd50",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd151fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DinosourBoneFinder()  # init model\n",
    "trainer = Trainer(model, epochs=6, ipx=True)  # set up trainer with the model\n",
    "tft = trainer.fine_tune(train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48061a-649c-41d8-bec1-e14fd68d7a79",
   "metadata": {},
   "source": [
    "# Compare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e460dd-49eb-42b7-a435-a1439cf9af24",
   "metadata": {},
   "source": [
    "# Save the model \n",
    "\n",
    "Save it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f49b8-a25d-481d-948e-05ef46628cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'resnet18_3Class_RN'\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(f'models/{modelName}.pt') # Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fdbef-93e8-4660-857a-6b4c2c6b132f",
   "metadata": {},
   "source": [
    "# Load a Saved Model\n",
    "\n",
    "Use this to load a previously created model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965f1e1-b04c-41d2-9441-1b5a0a3467f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'resnet18_3Class_RN'\n",
    "modelRead = torch.jit.load(f'models/{modelName}.pt')\n",
    "modelRead.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cca1f5-7175-41f7-94ea-50c299176d81",
   "metadata": {},
   "source": [
    "# Infer Function\n",
    "\n",
    "Used to score and get associted filename for each scored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92ad1f-f331-4319-a42f-2483a8dc3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose \n",
    "    labels have to be predicted are kept.\n",
    "    \n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        yhat = model(imgs)\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "    return images, yhats, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ad634-b1b5-456b-a47c-9a7b30de7ddb",
   "metadata": {},
   "source": [
    "## Using Infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228abb78-54e6-4231-b1f8-77826271f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir  data/ThreeClassManualRemove0s/test\n",
    "!mkdir  data/ThreeClassManualRemove0s/test/unknown\n",
    "!cp data/DinosaurNationalMonument/20220514/224/*.jpg data/ThreeClassManualRemove0s/test/unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebabad9-84cb-4dfe-ac4f-b63b4e76739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, yhats, img_paths = infer(model, data_path=\"./data/ThreeClassManualRemove0s/test/\")\n",
    "# infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "# print(\"infered images with labels\")\n",
    "# show_data(infer_dataloader, imagenet_stats, 10, figsize=(20, 8))\n",
    "\n",
    "input_size = 224\n",
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "images, yhats, img_paths = infer(modelRead, data_path=\"./data/ThreeClassManualRemove0s/test/\")\n",
    "infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "print(\"infered images with labels\")\n",
    "show_data(infer_dataloader, imagenet_stats, 10, figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a7750-c224-45df-b4c0-911c0179ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(yhats, img_paths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1733b34285ed74833bcb8e1b7a940727029b0435f34e09e572d05f37d583a466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
