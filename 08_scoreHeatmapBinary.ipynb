{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef6809f-b4e1-4e33-a549-1a00ae11ec84",
   "metadata": {},
   "source": [
    "# Heatmap Generation\n",
    "\n",
    "Use model to inference a new map\n",
    "\n",
    "<img src=\"assets/HeatMap.png\" width=\"640\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d53e-30c5-49c6-9c8b-173a6ae048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c0d8f-bef7-412a-8261-ef13592045e1",
   "metadata": {},
   "source": [
    "# Specify Model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e456-a8b0-45c5-9991-ff74ea0a5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = False\n",
    "epochs = 6\n",
    "ipx = True \n",
    "dropout = .5\n",
    "batch_size = 128\n",
    "# bc_resnet18_simpleFalse_IPEXTrue_Epochs12_dropout0.4_batch128\n",
    "#model_name = \"bc_resnet18_simple_NOIPEX_6Epochs_gold\"\n",
    "#resnet18_simpleFalse_IPEXTrue_Epochs12_dropout0.4_batch128\n",
    "#ON_resnet18_simpleFalse_IPEXTrue_Epochs6_dropout0.5_batch128\n",
    "model_name = f\"ON_resnet18_simple{simple}_IPEX{ipx}_Epochs{epochs}_dropout{dropout}_batch{batch_size}\"\n",
    "print(model_name)\n",
    "model_read = torch.jit.load(f\"models/{model_name}.pt\")\n",
    "model_read.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc7762-8eba-4749-bbc2-d33b63ca18b8",
   "metadata": {},
   "source": [
    "# Define functions and normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44ef35-ffa1-4eb4-a6b7-e7bde0cd1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"custom ImageFolder to get the filepaths along with the image and label data.\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose\n",
    "    labels have to be predicted are kept.\n",
    "\n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "\n",
    "    returns: (\n",
    "        images: images loaded from disk for inferece,\n",
    "        yhats: predicted labels\n",
    "        paths: image file-path on disk        )\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        yhat = model(imgs)\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "    return images, yhats, paths\n",
    "\n",
    "def show_data(dataloader, imagenet_stats=imagenet_stats, num_data=4, figsize=(10, 6)):\n",
    "    \"\"\"show `num_data` of images and labels from dataloader.\"\"\"\n",
    "    batch = next(iter(dataloader))  # batch of with images, batch of labels\n",
    "    imgs, labels = (\n",
    "        batch[0][:num_data],\n",
    "        batch[1][:num_data].tolist(),\n",
    "    )  # get num_data of images, labels\n",
    "    plt.style.use(\"dark_background\")\n",
    "    _, axes = plt.subplots(1, num_data, figsize=figsize)\n",
    "    for n in range(num_data):\n",
    "        axes[n].set_title(labels[n])\n",
    "        imgs[n] = _denormalize(imgs[n], imagenet_stats)\n",
    "        axes[n].imshow(torch.clamp(imgs[n], 0, 1).permute(1, 2, 0))\n",
    "\n",
    "def _denormalize(images, imagenet_stats):\n",
    "    \"\"\"de normalize dataset using imagenet std and mean to show images\"\"\"\n",
    "    mean = torch.tensor(imagenet_stats[0]).reshape(1, 3, 1, 1)\n",
    "    std = torch.tensor(imagenet_stats[1]).reshape(1, 3, 1, 1)\n",
    "    return images * std + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25657580-a0d3-4cdf-95fb-34358d271797",
   "metadata": {},
   "source": [
    "# Prepare final test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb9840-d28a-4f62-a16e-62513576bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data/ThreeClassManualRemove0s/test\n",
    "# !mkdir  data/ThreeClassManualRemove0s/test/unknown\n",
    "# !cp data/DinosaurNationalMonument/20220514/224/*.jpg data/ThreeClassManualRemove0s/test/unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196e3db-7bdd-4dbb-b826-cde1147e2f9b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6b8e2-90a0-416e-ac73-f0c755099072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "# images, yhats, img_paths = infer(\n",
    "#     model_read, data_path=\"./data/geemap/val/\"\n",
    "# )\n",
    "# infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "# print(\"infered images with labels\")\n",
    "# show_data(infer_dataloader, imagenet_stats, 20, figsize=(20, 16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111421d-cd6e-4cc7-b0bd-576f7ecbb21f",
   "metadata": {},
   "source": [
    "# Inference Given Large Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5adea7a-6963-4c42-b43f-2ce55ea5a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from os.path import exists\n",
    "import os\n",
    "path = \"data/DinosaurNationalMonument/m_4010938_ne_12_060_20211004_bc_cropped2.png\"\n",
    "#path = \"data/Explore/Pombal01.PNG\"\n",
    "\n",
    "img = Image.open(path).convert('RGB')\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7918056-62df-4b2e-8c45-151c3b4b6c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0acd4d75-ef40-4c55-96bd-91d3f9e1206a",
   "metadata": {},
   "source": [
    "# Get sample near DNM Excavation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c91fa2-7928-4bf5-9922-1a0b3090ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = 4*224+270\n",
    "low = 4*224+233\n",
    "\n",
    "bbox = (left, low, left + 224, low + 224)\n",
    "working_slice = img.crop(bbox)\n",
    "working_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3d10a-e7af-48ff-a4b3-3a1c0c4995d6",
   "metadata": {},
   "source": [
    "# Simple eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836302a0-e03d-4ee0-9953-4259dc723251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import time\n",
    "\n",
    "def transform_image(image):\n",
    "    my_transforms = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(\n",
    "                                            [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])])\n",
    "    return my_transforms(image).unsqueeze(0)\n",
    "\n",
    "def eval_simple(working_slice):\n",
    "    x = transform_image(working_slice)\n",
    "    output = model_read(x)\n",
    "    return output.detach().numpy().argmax()\n",
    "st = time.time()\n",
    "eval_simple(working_slice)\n",
    "print( time.time() -st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdad515-859a-4a97-96ab-5b05d892f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"custom ImageFolder to get the filepaths along with the image and label data.\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose\n",
    "    labels have to be predicted are kept.\n",
    "\n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "\n",
    "    returns: (\n",
    "        images: images loaded from disk for inferece,\n",
    "        yhats: predicted labels\n",
    "        paths: image file-path on disk        )\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=16,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    \n",
    "    infer_time_sum = 0\n",
    "    start_time = time.perf_counter()\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        start = time.perf_counter()\n",
    "        yhat = model(imgs)\n",
    "        end = time.perf_counter()\n",
    "        time_torch = end - start\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "        infer_time_sum += time_torch\n",
    "    end_time = time.perf_counter()    \n",
    "    print(\n",
    "        f\"PyTorch model on CPU with batch inference: {infer_time_sum} total time, \"\n",
    "    )\n",
    "    print(\"Overall running time elapsed for PyTorch format batch inference: \", end_time - start_time)\n",
    "    return images, yhats, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1201c-a241-4ae2-8b4e-36ed76c3a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "# images, yhats, img_paths = infer(\n",
    "#     model_read, data_path=\"./data/DinosaurNationalMonument/224/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75ba51-430b-45c2-8251-fa642292a169",
   "metadata": {},
   "source": [
    "# Read large image and score it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16761e-75a1-460d-949a-a1a0777b30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from os.path import exists\n",
    "import os\n",
    "\n",
    "img = Image.open(path).convert('RGB')\n",
    "\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "countBuf = np.ones( (img.size[0], img.size[1]) )\n",
    "sumBuf   = np.zeros( (img.size[0], img.size[1]) )\n",
    "\n",
    "start = time.time()\n",
    "step = 28  # choose a factor of 224: 1, 2, 4, 7, 8, 14, 16, 28, 32, 56, 112, and 224. Small is smooth map, large is fast\n",
    "counts = {0:0, 1:0, 2:0}\n",
    "scale = {0:1, 1:0, 2:0}  # score dictinary mapping raw score to weight to be used, Morrison = 0\n",
    "for x in tqdm(range(0, img.size[0]-224, step)):\n",
    "    for y in range(0, img.size[1]-224, step):  \n",
    "        bbox = (x, y, x + 224, y + 224)\n",
    "        working_slice = img.crop(bbox)\n",
    "        countBuf[bbox[0]:bbox[2], bbox[1]:bbox[3]] += 1\n",
    "        sumBuf[bbox[0]:bbox[2], bbox[1]:bbox[3]] += scale[eval_simple(working_slice)]\n",
    "print(f\"step size = {step}, Elapsed: {(time.time() - start):6.1f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812aaa47-69c2-48a6-89ee-e4a3d6b90b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9763a6-5356-4efa-8a4a-cc1702ab9605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c236c0-3479-47f9-a0d1-2eb2a5cde492",
   "metadata": {},
   "source": [
    "# Matplotlib bilinear interpolation map approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d6e50-72ee-4ed1-b697-3bdfc9677fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(sumBuf.T, cmap='rainbow', interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365d563-bb10-46c1-bd44-04ffa8aaeb88",
   "metadata": {},
   "source": [
    "# Compute the mean of scores for sliding tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae35ef3-fe56-430d-813f-878c547c5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set opacity to 159: 0 is transparent, 255 is opaque\n",
    "meanBuf = sumBuf/countBuf\n",
    "mat = np.uint8(meanBuf.T*159/meanBuf.max()) # scale the opacity: 0 transpartent, 255 solid\n",
    "idx = mat < 0\n",
    "mat[idx] = 0\n",
    "output = Image.fromarray(mat)\n",
    "output.save('results/bobTile.png')\n",
    "np.save('results/meanBuf.npy', mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246745ef-6357-4030-82a3-ca770928a84a",
   "metadata": {},
   "source": [
    "# Heatmap Approach\n",
    "\n",
    "Color Legend:\n",
    "- Bright Red: Bones more likely\n",
    "- Bright Blue: Bone not likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f5e23-bd0f-4e32-ac3b-c0b14c115c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(path)\n",
    "alpha = np.load('results/meanBuf.npy')\n",
    "\n",
    "imgcv = Image.open(path.replace('.jpg','.PNG'))\n",
    "heatmap_img = np.copy(imgcv)\n",
    "alpha1D = alpha/alpha.max()*255\n",
    "\n",
    "heatmap_img[:,:,0] = alpha1D\n",
    "heatmap_img[:,:,1] = 255 - alpha1D\n",
    "heatmap_img[:,:,2] = 255 - alpha1D\n",
    "\n",
    "opacity = .5\n",
    "imgHeat = Image.blend(Image.fromarray(heatmap_img), imgcv, alpha=0.5)\n",
    "imgHeat.save('results/HeatMap.png')\n",
    "print(model_name)\n",
    "print(\"Color Legend:\\n- Red: Higher Probability\\n- Blue: -Lower Probability\")\n",
    "#imgHeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a370a8-14b5-44ad-ad9f-12454c0baf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumBuf.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3333ac-67e6-40da-a456-89f1834234c6",
   "metadata": {},
   "source": [
    "# Display the HeatMap\n",
    "\n",
    "<img src=\"results/HeatMap.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500f665-21dc-450e-95d3-66d0cc812d15",
   "metadata": {},
   "source": [
    "## Notices and Disclaimers\n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "\n",
    "No product or component can be absolutely secure. \n",
    "\n",
    "Your costs and results may vary. \n",
    "\n",
    "Â© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dcd37-4e5f-4331-ad10-0408523c22f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
