{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ceeedd3-8726-4c87-a13e-c8359faae012",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Resnet\n",
    "\n",
    "The labeled data should be stored according to a specified folder structure as follows:\n",
    "\n",
    "<img src=\"assets/FolderStructure.jpg\" width=\"500\"/>\n",
    "\n",
    "We will experiment with training against this dataset using resnet18 resnet34, resnet50 and so forth\n",
    "\n",
    "The experiments will span pretrained = True/False \n",
    "with various hyperparameters.\n",
    "\n",
    "These models will be trained against data collected from central New Mexico. The waypoint information is NOT provided. These models will achieve accuracies above 90% and do a great job of mapping the central New Mexico Jurassic Morrison formation. \n",
    "\n",
    "The real challenge is to SCORE similar geological depositional envirnoments in other parts of the US - for example in Utah.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852da76-1763-4ef8-9961-9dfe14215a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97340e-2086-49ba-8967-0b0cb3865935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "classes = 3\n",
    "lr = 3e-4 #3e-4\n",
    "batch_size = 64  #64\n",
    "modelName = \"resnet34\"\n",
    "logfn = f\"logfile{modelName}_Bat{batch_size:03d}_LR{lr:5.0g}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO, filename= logfn, filemode=\"a+\",\n",
    "                        format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "    \n",
    "n_epochs = 20\n",
    "\n",
    "# SGD\n",
    "momentum = .9\n",
    "\n",
    "# Adam\n",
    "betas = (0.9, 0.999)   # Adam betas: It is used as a parameter that calculates the averages of the gradient.\n",
    "weight_decay = 1e-4   # for Adam control regularization\n",
    "\n",
    "padding = 47\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "[\n",
    "    transforms.Pad(padding),\n",
    "    transforms.RandomAffine(degrees=360,scale=(.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root= \"data/ThreeClassManualRemove0s/train/\", transform=transforms)\n",
    "test_dataset = datasets.ImageFolder(root= \"data/ThreeClassManualRemove0s/val/\", transform=transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \n",
    "    inp = inp.cpu() if device else inp\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "if modelName == 'resnet18':\n",
    "    net = models.resnet18(pretrained=True)\n",
    "if modelName == 'resnet34':\n",
    "    net = models.resnet34(pretrained=False)\n",
    "if modelName == 'resnet50':\n",
    "    net = models.resnet50(pretrained=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9692e52-c2ef-4d65-94ad-52cda2a7a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr= lr, momentum= momentum)\n",
    "optimizer = optim.Adam(net.parameters(), lr = lr, betas = betas, weight_decay = weight_decay)\n",
    "logging.info(f\"model {modelName}\") \n",
    "logging.info(\"optim.Adam\")\n",
    "logging.info(\"batch_size = {}\".format(batch_size))\n",
    "logging.info(\"lr = {}\".format(lr))\n",
    "logging.info(\"betas = {}\".format(betas))\n",
    "logging.info(\"weight_decay = {}\".format(weight_decay))\n",
    "logging.info(\"image padding = {}\".format(padding))\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n",
    "\n",
    "num_ftrs = net.fc.in_features\n",
    "# net.fc = nn.Sequential(\n",
    "#     nn.Dropout(0.25),\n",
    "#     nn.Linear(num_ftrs, classes)\n",
    "# )\n",
    "net.fc = nn.Linear(num_ftrs, classes)\n",
    "net.fc\n",
    "# pick up where last one died - code below\n",
    "#net.load_state_dict(torch.load('resnet-GOLD94Perc_ThreeClass.pt'))\n",
    "#net.load_state_dict(torch.load(f'{modelName}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604ea8d-ef50-4565-8c40-c7a29b712408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a42ae-ea1d-4cfd-acdc-95b3a89c983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_dataloader)\n",
    "EpochStart = time.time()\n",
    "batchPrint = batchPrint =  int(len(train_dataset)/batch_size/5 ) # 8\n",
    "startEpoch = time.time()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    lastEpoch = time.time()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Model: {modelName}\\t Batch size: {batch_size}\\tEpoch: {epoch}\\tLearning rate: {lr}\\n')\n",
    "    logging.info(f'Model: {modelName}\\t Batch size: {batch_size}\\tEpoch: {epoch}\\tLearning rate: {lr}\\n')\n",
    "    logging.info('-' * 10)\n",
    "    lastStep = time.time()\n",
    "    \n",
    "    for batch_idx, (data_, target_) in enumerate(train_dataloader):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % batchPrint == 0:\n",
    "            print ('Epoch [{}/{}]\\tStep [{}/{}]\\tLoss: {:.4f}\\tStep Time {:4.1f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item(), time.time() - lastStep))\n",
    "            lastStep = time.time()\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'train-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    temp = f'train-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}'\n",
    "    logging.info(temp)     \n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (test_dataloader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(test_dataloader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "        temp = f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n'\n",
    "        logging.info(temp) \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(net.state_dict(), f'models/{modelName}.pt')\n",
    "            torch.save(net, f'models/{modelName}.full.pt')\n",
    "            print('Improvement-Detected, save-model')\n",
    "            logging.info('Improvement-Detected, save-model') \n",
    "    net.train()\n",
    "    print(f\"Epoch time: {time.time() - lastEpoch:5.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba551f89-0003-4405-aad8-878f058500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(test_dataloader)\n",
    "# images, labels = dataiter.next()\n",
    "# images = images.numpy() \n",
    "\n",
    "# fig = plt.figure(figsize=(25,4))\n",
    "# for idx in np.arange(10):\n",
    "#     ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
    "#     plt.imshow(np.transpose(images[idx], (1,2,0)).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124b055-12e7-45c0-a224-5d2ca60bd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d09b8-bd2d-40c8-ac94-6dcab55a9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Violence Class\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "def scoreSingleImage(ImagePath, model, dataset_classes):\n",
    "    from PIL import Image\n",
    "    import torch.nn.functional as F\n",
    "    from torch.autograd import Variable\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    img = Image.open(ImagePath)    \n",
    "    x_test = data_transforms['val'](img)[:3]   #3 channels in case png bobc\n",
    "    x_test.unsqueeze_(0)  # Add batch dimension\n",
    "    x_test2 = Variable(x_test)\n",
    "    output = model(x_test)\n",
    "    class_names = dataset_classes\n",
    "    predArgmax = torch.argmax(output[0]).numpy()\n",
    "    confidence = F.softmax(output, dim=0)\n",
    "    score = []\n",
    "    score.append( class_names[predArgmax] )\n",
    "    score.append( float(confidence[0][predArgmax]) )\n",
    "    return score \n",
    "\n",
    "def calc_metrics(tp_rowcol, cm):\n",
    "    # this works only for col 0, row 0 for now \n",
    "    #will troubleshoot other columns later\n",
    "    # so its works for Violence but i have not generalized the cal to accomdate other row,col as the tp\n",
    "\n",
    "    tmp = 0\n",
    "    tp_rowcol = -tp_rowcol\n",
    "    tmp = np.roll(cm, tp_rowcol, axis=1)\n",
    "    cm = np.roll(tmp, tp_rowcol, axis=0)  \n",
    "\n",
    "    L = len(cm)\n",
    "    tp = cm[0][0]\n",
    "    fn = sum(cm[0][1:L])\n",
    "    fp = sum(cm, axis = 0)[0] - tp\n",
    "    ftn = sum(cm, axis = 0) - cm[0]\n",
    "    tn = sum(cm[1:L,1:L])\n",
    "    sensitivity_recall =  tp  / (tp + fn + 0.)\n",
    "    specificity =  tn / (tn + fp + 0.)\n",
    "    precision =  tp / (tp + fp + 0.)\n",
    "    accuracy =  (tp+tn+ 0.)/(tp+fp+fn+tn + 0.)\n",
    "    f1 = 2.0*precision*sensitivity_recall/(precision+sensitivity_recall)\n",
    "    return(accuracy, precision, sensitivity_recall, specificity, f1)\n",
    "def print_metrics(accuracy, precision, sensitivity_recall, specificity, f1):\n",
    "    print ('accuracy: ', accuracy)\n",
    "    print ('sensitivity_recall: ',sensitivity_recall)\n",
    "    print ('specificity: ', specificity)\n",
    "    print ('precision: ', precision)\n",
    "    print ('f1: ', f1)\n",
    "def metricsAsDataframe(accuracy, precision, sensitivity_recall, specificity, f1):\n",
    "    data = [{'metric': 'accuracy', 'Value': accuracy, 'Description': '(tp+tn)/(tp+fp+fn+tn)'},\n",
    "             {'metric': 'precision',  'Value': precision, 'Description': 'tp/(tp+fp)' },\n",
    "             {'metric': 'sensitivity_recall',  'Value': sensitivity_recall, 'Description': 'tp  / (tp + fn)'},\n",
    "             {'metric': 'specificity',  'Value': specificity,  'Description': 'tn / (tn + fp)'},\n",
    "            {'metric': 'F1',  'Value': f1,  'Description': '2*precision*recall/(precision+recall)'}]\n",
    "    dfObj = pd.DataFrame(data, columns=['metric', 'Value', 'Description'])\n",
    "    return dfObj\n",
    "\n",
    "input_size = 224\n",
    "data_dir = \"data/ThreeClassManualRemove0s/\"\n",
    "\n",
    "batch_size = 64\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79852a6b-9684-4fc6-aef3-59bc3ea150d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['0', '1', '2']\n",
    "filename = 'data/ThreeClassBalanced5000/train/2/Batwing07.png'\n",
    "pred = scoreSingleImage(filename, net, my_classes)\n",
    "print(filename, pred[0])\n",
    "\n",
    "filename = 'data/ThreeClassBalanced5000/val/0/HFNoBone029.png'\n",
    "pred = scoreSingleImage(filename, net, my_classes)\n",
    "print(filename, pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbce25-fd8c-49bc-9535-2ddf4156eb4d",
   "metadata": {},
   "source": [
    "# Score val folder to print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6f91b-f0c1-411d-ab54-702db64667cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "my_classes = ['0', '1', '2']\n",
    "data_dir = \"data/ThreeClassManualRemove0s/\"\n",
    "files = []\n",
    "class_pred = []\n",
    "class_true = []\n",
    "for fl in my_classes:\n",
    "    path = data_dir + 'val/' + fl + '/'\n",
    "    for filename in glob.glob(os.path.join(path, '*.png')):\n",
    "        files.append(filename)\n",
    "        try: \n",
    "            pred = scoreSingleImage(filename, net, my_classes)\n",
    "            class_pred.append(pred[0])\n",
    "            class_true.append(filename.split('/')[-2])\n",
    "            if class_pred[-1] != class_true[-1]:\n",
    "                print(\"pred: \", class_pred[-1], \"  true: \", class_true[-1], filename)\n",
    "        except:\n",
    "            print (\"File not compatible (channels)\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c5070-722a-4c5d-8967-6573bcb417ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import *\n",
    "import sys\n",
    "from pylab import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = class_true\n",
    "y_pred = class_pred\n",
    "\n",
    "myset = set(y_true)\n",
    "labels = list(myset)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred,  labels= my_classes)\n",
    "cmd = cm.copy()\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
