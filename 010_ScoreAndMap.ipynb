{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fa44a6-07af-4996-8290-0314e0c89cbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Score Dinosaur National Monument w Binary Model\n",
    "\n",
    "Each green square is roughly 260m x 260m or about 2.5 times the length of a soccer of football field\n",
    "\n",
    "![assets/DNM_ThreeClassMainCircled.jpg](assets/DNM_ThreeClassMainCircled.jpg)\n",
    "\n",
    "Even though this model was trained on images and data from  New Meciso it predicts very well in Utah\n",
    "\n",
    "The red circled building is the famous Dinosaur National Monument buildig housing the bones still being excavated from teh site.\n",
    "\n",
    "The site was discovered in 1909 by paleontologist Earl Douglass of the Carnegie Museum \n",
    "\n",
    "\n",
    "![assets/DNM_Camarasaurus.jpg](assets/DNM_Camarasaurus.jpg)\n",
    "\n",
    "Essentially, the New Mexico trained model, predicts Bones likley at the site of this building\n",
    "\n",
    "This is based on the texture and color of the depotiional environments of sandstones and claystones of the Brushy Basin member of the Morrison Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa114f28-c133-4d6b-8270-aabcc6d9dbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "scratch_model = models.resnet18(pretrained=True)\n",
    "num_ftrs = scratch_model.fc.in_features\n",
    "classes = 3\n",
    "scratch_model.fc = nn.Linear(num_ftrs, classes)\n",
    "scratch_model.load_state_dict(torch.load('resnet18-Gold20220530.pt'))\n",
    "#scratch_model.load_state_dict(torch.load('resnet34.pt'))\n",
    "map_save = 'data/MoabDinoTrail_ThreeClassBalanced.jpg'\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "input_size = 224\n",
    "data_dir = \"data/ThreeClassManualRemove0s/\"\n",
    "\n",
    "batch_size = 64\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device: {}\".format(device))\n",
    "\n",
    "\n",
    "files = []\n",
    "class_true = []\n",
    "class_pred = []\n",
    "#my_classes = ['Bone', 'NoBone']\n",
    "my_classes = image_datasets['val'].classes\n",
    "\n",
    "green = Image.new('RGBA',(224,224),(0,255,0,60))\n",
    "white = Image.new('RGBA',(224,224),(255,255,255,1))\n",
    "lightGreen = Image.new('RGBA',(224,224),(0,255,0,20))\n",
    "black = Image.new('RGBA',(224,224),(0,0,0,1))\n",
    "\n",
    "\n",
    "def DatasetSizes(dataset_ReadClassChoices):\n",
    "    dataset_sizes = {x: len(dataset_ReadClassChoices[x]) for x in ['train', 'val']}\n",
    "    return dataset_sizes\n",
    "\n",
    "def scoreSingleImage(ImagePath, model, dataset_classes):\n",
    "    from PIL import Image\n",
    "    import torch.nn.functional as F\n",
    "    from torch.autograd import Variable\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    img = Image.open(ImagePath).convert('RGB') \n",
    "    x_test = data_transforms['val'](img)[:3]   #3 channels in case png bobc\n",
    "    x_test.unsqueeze_(0)  # Add batch dimension\n",
    "    x_test2 = Variable(x_test)\n",
    "    output = model(x_test)\n",
    "    class_names = dataset_classes\n",
    "    predArgmax = torch.argmax(output[0]).numpy()\n",
    "    confidence = F.softmax(output, dim=0)\n",
    "    score = []\n",
    "    score.append( class_names[predArgmax] )\n",
    "    score.append( float(confidence[0][predArgmax]) )\n",
    "    return score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e42fd-f193-4ac2-8164-f01ee07560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/ThreeClassBalanced5000/train/2/Batwing07.png'\n",
    "scoreSingleImage(filename, scratch_model, my_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80580af9-aca4-4d9e-9479-09a386ed0947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f52c10de-219f-4fc6-bdcb-64e8dd3b7b07",
   "metadata": {},
   "source": [
    "# Score val folder to print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10dce4-98ad-40f2-b4b0-bcd5448a6905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30485290-7b06-4347-bda1-dad61cd1b708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fa09b-71d4-4dd3-bc66-e3a3b6e67c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/Moab Dino Trail 16 NoBone Area.PNG')\n",
    "XR, YR = img.size\n",
    "XR, YR = XR//224, YR//224\n",
    "print(XR, YR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d8791-39dd-4e04-979e-8d6e0ba8be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pngFolder = 'data/UT_Vac3/'\n",
    "for fn in glob.glob(pngFolder + '*.png'):\n",
    "    img = Image.open(fn)\n",
    "    r, g, b = img.convert('RGB').split()\n",
    "    if g.histogram()[0] + r.histogram()[0] + b.histogram()[0] > 223*3:\n",
    "        print(fn,\" remove: has black stripe\")\n",
    "        os.remove(fn, dir_fd=None)\n",
    "    img.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8c5ec-5e26-4aca-a2e3-c56fbe3ac1cf",
   "metadata": {},
   "source": [
    "# Score 20220514/224\n",
    "\n",
    "Best map to score\n",
    "\n",
    "Green square roughly 265 m x 265 m -  about 2.5 football or soccer fields long\n",
    "\n",
    "The are in Green is a significantly smaller search are than the entire map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bf7f3-b4c5-4140-9096-6503383e6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from os.path import exists\n",
    "\n",
    "green = Image.new('RGBA',(224,224),(0,255,0,75))\n",
    "white = Image.new('RGBA',(224,224),(255,255,255,1))\n",
    "lightGreen = Image.new('RGBA',(224,224),(0,255,0,40))\n",
    "black = Image.new('RGBA',(224,224),(0,0,0,1))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for x in range(XR):\n",
    "    for y in range(YR):\n",
    "        filename = 'data/UT_Vac3/DNMx{:03d}y{:03d}.png'.format(x, y)\n",
    "        filenameMap = 'data/UT_Vac3/224Map/DNMx{:03d}y{:03d}.png'.format(x, y)\n",
    "        if exists(filename):\n",
    "            img = Image.open(filename).convert('RGB')\n",
    "            try: \n",
    "                pred = scoreSingleImage(filename, scratch_model, my_classes)[0]\n",
    "                print(pred, filename)\n",
    "                if pred[0] == '2':\n",
    "                    Image.alpha_composite(img.convert(\"RGBA\"), green).save(filenameMap)\n",
    "                elif pred[0] == '1': \n",
    "                    Image.alpha_composite(img.convert(\"RGBA\"), lightGreen).save(filenameMap)\n",
    "                else:\n",
    "                    Image.alpha_composite(img.convert(\"RGBA\"), black).save(filenameMap)\n",
    "                class_pred.append(pred[0])\n",
    "                class_true.append(filename.split('/')[-2])\n",
    "            except:\n",
    "                print (\"Problem\", x, y, filename)\n",
    "print(\"Scoring time elapsed: \", time.time() - start) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f33d7-8a94-43f8-bf2f-510e3599650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSingleImage(filename, scratch_model, my_classes)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fee9d-0528-492f-8dd4-b10e313a1c65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge Dinosaur National Monument merged 20220514/224\n",
    "\n",
    "![assets/Re-assembleTilesIntoMap.PNG](assets/Re-assembleTilesIntoMap.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f98587-42e8-4a56-ac55-ac58a2fbe573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "xblock = XR\n",
    "yblock = YR\n",
    "dst = Image.new('RGB', ((xblock - 1)*224, (yblock - 1)*224))\n",
    "for x in range(xblock):\n",
    "    for y in range(yblock):\n",
    "        path = 'data/UT_Vac3/224Map/DNMx{:03d}y{:03d}.png'.format(x,y)\n",
    "        if exists(path):\n",
    "            img = Image.open(path)\n",
    "            dst.paste(img, (x*224, y*224))\n",
    "            img.close()\n",
    "dst.save(map_save)\n",
    "print(map_save)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23200297-93c5-42e8-853b-631f652c701c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (IntelÂ® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
