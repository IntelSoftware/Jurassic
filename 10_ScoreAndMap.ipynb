{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fa44a6-07af-4996-8290-0314e0c89cbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 10 Score Dinosaur National Monument with Binary Model\n",
    "\n",
    "Each green square is roughly 260m x 260m or about 2.5 times the length of a soccer of football field\n",
    "\n",
    "<img src=\"assets/DNM_ThreeClassMainCircled.jpg\" width=\"500\"/>\n",
    "\n",
    "Even though this model was trained on images and data from New Mexico it predicts very well in Utah\n",
    "\n",
    "The red circled building is the famous Dinosaur National Monument building housing the bones still being excavated from the site.\n",
    "\n",
    "The site was discovered in 1909 by paleontologist Earl Douglass of the Carnegie Museum \n",
    "\n",
    "<img src=\"assets/DNM_Camarasaurus.jpg\" width=\"500\"/>\n",
    "\n",
    "Essentially, the New Mexico trained model, predicts Bones likely at the site of this building\n",
    "\n",
    "This is based on the texture and color of the depositional environments of sandstones and claystone’s of the Brushy Basin member of the Morrison Formation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa114f28-c133-4d6b-8270-aabcc6d9dbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "scratch_model = models.resnet18(pretrained=True)\n",
    "num_ftrs = scratch_model.fc.in_features\n",
    "classes = 3\n",
    "scratch_model.fc = nn.Linear(num_ftrs, classes)\n",
    "scratch_model.load_state_dict(torch.load('models/resnet18-Gold20220530.pt'))\n",
    "#scratch_model.load_state_dict(torch.load('resnet34.pt'))\n",
    "#map_save = 'data/MoabDinoTrail_ThreeClassBalanced.jpg'\n",
    "map_save = 'data/GreenColoradoRiversScoreMapped.PNG'\n",
    "map_save = 'data/Moab 16 NoBone AreaScoreMapped.PNG'\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "input_size = 224\n",
    "data_dir = \"data/ThreeClassManualRemove0s/\"\n",
    "\n",
    "batch_size = 64\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device: {}\".format(device))\n",
    "\n",
    "\n",
    "files = []\n",
    "class_true = []\n",
    "class_pred = []\n",
    "#my_classes = ['Bone', 'NoBone']\n",
    "my_classes = image_datasets['val'].classes\n",
    "\n",
    "green = Image.new('RGBA',(224,224),(0,255,0,60))\n",
    "white = Image.new('RGBA',(224,224),(255,255,255,1))\n",
    "lightGreen = Image.new('RGBA',(224,224),(0,255,0,20))\n",
    "black = Image.new('RGBA',(224,224),(0,0,0,1))\n",
    "\n",
    "\n",
    "def DatasetSizes(dataset_ReadClassChoices):\n",
    "    dataset_sizes = {x: len(dataset_ReadClassChoices[x]) for x in ['train', 'val']}\n",
    "    return dataset_sizes\n",
    "\n",
    "def scoreSingleImage(ImagePath, model, dataset_classes):\n",
    "    from PIL import Image\n",
    "    import torch.nn.functional as F\n",
    "    from torch.autograd import Variable\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    img = Image.open(ImagePath).convert('RGB') \n",
    "    x_test = data_transforms['val'](img)[:3]   #3 channels in case png bobc\n",
    "    x_test.unsqueeze_(0)  # Add batch dimension\n",
    "    x_test2 = Variable(x_test)\n",
    "    output = model(x_test)\n",
    "    class_names = dataset_classes\n",
    "    predArgmax = torch.argmax(output[0]).numpy()\n",
    "    confidence = F.softmax(output, dim=0)\n",
    "    score = []\n",
    "    score.append( class_names[predArgmax] )\n",
    "    score.append( float(confidence[0][predArgmax]) )\n",
    "    return score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e42fd-f193-4ac2-8164-f01ee07560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/ThreeClassBalanced5000/train/2/Batwing07.png'\n",
    "scoreSingleImage(filename, scratch_model, my_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80580af9-aca4-4d9e-9479-09a386ed0947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f52c10de-219f-4fc6-bdcb-64e8dd3b7b07",
   "metadata": {},
   "source": [
    "# Score val folder to print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10dce4-98ad-40f2-b4b0-bcd5448a6905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30485290-7b06-4347-bda1-dad61cd1b708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fa09b-71d4-4dd3-bc66-e3a3b6e67c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/Moab 16 NoBone Area.PNG')\n",
    "XR, YR = img.size\n",
    "XR, YR = XR//224, YR//224\n",
    "print(XR, YR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d8791-39dd-4e04-979e-8d6e0ba8be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pngFolder = 'data/UT_Vac3/'\n",
    "pngFolder = 'data/Moab 16 NoBone Area/'\n",
    "for fn in glob.glob(pngFolder + '*.png'):\n",
    "    img = Image.open(fn)\n",
    "    r, g, b = img.convert('RGB').split()\n",
    "    if g.histogram()[0] + r.histogram()[0] + b.histogram()[0] > 223*3:\n",
    "        print(fn,\" remove: has black stripe\")\n",
    "        os.remove(fn, dir_fd=None)\n",
    "    img.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8c5ec-5e26-4aca-a2e3-c56fbe3ac1cf",
   "metadata": {},
   "source": [
    "# Score 20220514/224\n",
    "\n",
    "Best map to score\n",
    "\n",
    "Green square roughly 265 m x 265 m -  about 2.5 football or soccer fields long\n",
    "\n",
    "The are in Green is a significantly smaller search are than the entire map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bf7f3-b4c5-4140-9096-6503383e6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from os.path import exists\n",
    "\n",
    "green = Image.new('RGBA',(224,224),(0,255,0,75))\n",
    "white = Image.new('RGBA',(224,224),(255,255,255,1))\n",
    "lightGreen = Image.new('RGBA',(224,224),(0,255,0,40))\n",
    "black = Image.new('RGBA',(224,224),(0,0,0,1))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for x in range(XR):\n",
    "    for y in range(YR):\n",
    "        filename = '{}224/DNMx{:02d}y{:02d}.png'.format(pngFolder, x, y)\n",
    "        filenameMap = '{}/224Map/DNMx{:02d}y{:02d}.png'.format(pngFolder, x, y)\n",
    "        if exists(filename):\n",
    "            img = Image.open(filename).convert('RGB')\n",
    "            try: \n",
    "                pred = scoreSingleImage(filename, scratch_model, my_classes)[0]\n",
    "                print(pred, filename)\n",
    "                if pred[0] == '2':\n",
    "                    Image.alpha_composite(img.convert(\"RGBA\"), green).save(filenameMap)\n",
    "                elif pred[0] == '1': \n",
    "                    Image.alpha_composite(img.convert(\"RGBA\"), lightGreen).save(filenameMap)\n",
    "                else:\n",
    "                    Image.alpha_composite(img.convert(\"RGBA\"), black).save(filenameMap)\n",
    "                class_pred.append(pred[0])\n",
    "                class_true.append(filename.split('/')[-2])\n",
    "            except:\n",
    "                print (\"Problem\", x, y, filename)\n",
    "print(\"Scoring time elapsed: \", time.time() - start) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f33d7-8a94-43f8-bf2f-510e3599650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSingleImage(filename, scratch_model, my_classes)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fee9d-0528-492f-8dd4-b10e313a1c65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge Dinosaur National Monument merged 20220514/224\n",
    "\n",
    "<img src=\"assets/Re-assembleTilesIntoMap.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f98587-42e8-4a56-ac55-ac58a2fbe573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "xblock = XR\n",
    "yblock = YR\n",
    "dst = Image.new('RGB', ((xblock - 1)*224, (yblock - 1)*224))\n",
    "for x in range(xblock):\n",
    "    for y in range(yblock):\n",
    "        path = '{}224Map/DNMx{:02d}y{:02d}.png'.format(pngFolder, x,y)\n",
    "        if exists(path):\n",
    "            img = Image.open(path)\n",
    "            dst.paste(img, (x*224, y*224))\n",
    "            img.close()\n",
    "dst.save(map_save)\n",
    "print(map_save)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca17e6-6c03-4d95-83fc-96f3220ec4f0",
   "metadata": {},
   "source": [
    "# More Utah Examples of Predicted and Confirmed Dinosaur Beds\n",
    "\n",
    "<img src=\"assets/UtahTwoPredictedBoneSites.PNG\" width=\"500\"/>\n",
    "\n",
    "### UtahRaptor State Park Confirmation\n",
    "Looking at our recent finds based on AI map at UtahRaptor State Park\n",
    "\n",
    "Model using binary data classifaction:\n",
    "\n",
    "<img src=\"assets/Utah_URSP_BinaryClassPrediction.PNG\" width=\"500\"/>\n",
    "\n",
    "Model using Three Class data classifaction:\n",
    "\n",
    "<img src=\"assets/Utah_URSP_ThreeClassPrediction.PNG\" width=\"500\"/>\n",
    "\n",
    "### Mill Creek Dinosaur Trail known dinosaur bones\n",
    "\n",
    "Looking at known bones at Mill Creek Dinosaur trail - Three Class model\n",
    "\n",
    "<img src=\"assets/MillCreekDinoTrailPredictionThreeClass.PNG\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d39928-f5e0-42b2-8874-e145eb6456d7",
   "metadata": {},
   "source": [
    "# Models do NOT paint everything green\n",
    "\n",
    "### Examples of mapped No Bone Areas\n",
    "\n",
    "Region near confluence of Green and Colorado Rivers - I dont really predict bone here and this is what the model says:\n",
    "\n",
    "<img src=\"assets/GreenColoradoRiversScoreMapped.png\" width=\"500\"/>\n",
    "\n",
    "Region of near Dinosaur National Monument predating the Morrison formation - Dont predict any bones here either and map agrees:\n",
    "\n",
    "<img src=\"assets/Moab 16 NoBone AreaScoreMapped.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44576bf3-69b0-4426-b6fa-27ddd9a4194b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
