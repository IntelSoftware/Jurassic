{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d9ae70-0700-444d-b057-7f474dbb0876",
   "metadata": {},
   "source": [
    "# Build, Train & Score Model with PyTorch\n",
    "\n",
    "### Introduction: Rahul Nair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41264b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seaborn\n",
    "#%pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0c4b5-7a15-4177-a5c0-a8e3218fcb6f",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef53d2c-5c27-4bc0-80e5-e622ea6f3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febceda-0e2a-4d85-b368-3d4916e09879",
   "metadata": {},
   "source": [
    "# Print Software Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"ipex version: {ipex.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55612962-55d6-44e1-bb9b-8477750b2e66",
   "metadata": {},
   "source": [
    "# Define Utility Functions\n",
    "\n",
    "### seed_everything and set_env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed: int = 4242):\n",
    "    \"\"\"set all random seeds using `seed`\"\"\"\n",
    "    print(f\"seed set to: {seed}\")\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def set_env_vars() -> int:\n",
    "    \"\"\"set openMP and torch params\"\"\"\n",
    "    num_physical_cores = psutil.cpu_count(logical=False)\n",
    "    print(f\"setting omp num threads: {num_physical_cores}\")\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(num_physical_cores)\n",
    "    os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,compact,1,0\"\n",
    "    os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "    return num_physical_cores\n",
    "\n",
    "\n",
    "seed_everything(9342)\n",
    "num_physical_cores = set_env_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457215f-9c4e-42c8-b45c-edc473dd0dfe",
   "metadata": {},
   "source": [
    "# Define dataset transforms \n",
    "\n",
    "test and validation transforms are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, validation & test dataset transforms, test and validation transforms are the same\n",
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "img_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomApply(\n",
    "                [transforms.GaussianBlur(kernel_size=(1, 3), sigma=(1, 3))], p=0.2\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(180),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*imagenet_stats),\n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df446f6f-5bc1-4679-96b4-4bf169150a80",
   "metadata": {},
   "source": [
    "# Create dataset for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa503e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for Training and Validation\n",
    "num_physical_cores = psutil.cpu_count(logical=False)\n",
    "data_dir = pathlib.Path(\"./data/ThreeClassManualRemove0s/\")\n",
    "TRAIN_DIR = data_dir / \"train\"\n",
    "VALID_DIR = data_dir / \"val\"\n",
    "\n",
    "# no augmentation for test and validation data\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=img_transforms[\"train\"])\n",
    "test_data = datasets.ImageFolder(  \n",
    "    TRAIN_DIR, transform=img_transforms[\"valid\"]\n",
    ")\n",
    "valid_data = datasets.ImageFolder(VALID_DIR, transform=img_transforms[\"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e53288-526c-405f-bb7d-330813afd921",
   "metadata": {},
   "source": [
    "# Define Utility Functions\n",
    "\n",
    "### data_distribution and plot_data_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distribution(dataset=train_data, path: str = TRAIN_DIR) -> dict:\n",
    "    \"\"\"return dict of data distribtion of each class.\"\"\"\n",
    "    cls_count = dict.fromkeys(dataset.class_to_idx, 0)\n",
    "    for cls in cls_count.keys():\n",
    "        cls_count[cls] = len(fnmatch.filter(os.listdir(f\"{path}/{cls}\"), \"*.png\"))\n",
    "    return cls_count\n",
    "\n",
    "\n",
    "def plot_data_distribution(data_dist: dict, title: str = \"\"):\n",
    "    \"\"\"plot data distribution\"\"\"\n",
    "    cls, count = list(data_dist.keys()), list(data_dist.values())\n",
    "    p = sns.barplot(x=cls, y=count)\n",
    "    p.set_title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73fa45-ebf8-4eb0-bc89-9cffca812284",
   "metadata": {},
   "source": [
    "# Plot Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cda558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dist = data_distribution(train_data, path=TRAIN_DIR)\n",
    "plot_data_distribution(train_data_dist, \"train_data_dist\")\n",
    "print(f\"train data dist: {train_data_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_dist = data_distribution(valid_data, path=VALID_DIR)\n",
    "plot_data_distribution(valid_data_dist, \"valid_data_dist\")\n",
    "print(f\"valid data dist: {valid_data_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e455f5-daf7-4677-b47a-6888f151dbdd",
   "metadata": {},
   "source": [
    "# Create train and test dataset from train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcab709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test dataset from train_data\n",
    "dataset_len = len(train_data.targets)\n",
    "data_idx = [x for x in range(dataset_len)]\n",
    "train_idx, test_idx = train_test_split(\n",
    "    data_idx, test_size=0.3, stratify=train_data.targets, shuffle=True\n",
    ")\n",
    "train_data = torch.utils.data.Subset(train_data, train_idx)\n",
    "test_data = torch.utils.data.Subset(test_data, test_idx)\n",
    "print(f\" train, valid, test sizes: {len(train_data), len(test_data), len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687520e-c62e-4448-8ee3-58d7be98509c",
   "metadata": {},
   "source": [
    "# Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size)\n",
    "print(f\"batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b12237-bff8-470c-9ab1-ab85b7926036",
   "metadata": {},
   "source": [
    "# Define Utility Functions\n",
    "\n",
    "### _denormalize and show_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _denormalize(images, imagenet_stats):\n",
    "    \"\"\"de normalize dataset using imagenet std and mean to show images\"\"\"\n",
    "    mean = torch.tensor(imagenet_stats[0]).reshape(1, 3, 1, 1)\n",
    "    std = torch.tensor(imagenet_stats[1]).reshape(1, 3, 1, 1)\n",
    "    return images * std + mean\n",
    "\n",
    "\n",
    "def show_data(dataloader, imagenet_stats=imagenet_stats, num_data=4, figsize=(10,6)):\n",
    "    \"\"\"show `num_data` of images and labels from dataloader.\"\"\"\n",
    "    batch = next(iter(dataloader))  # batch of with images, batch of labels\n",
    "    imgs, labels = (\n",
    "        batch[0][:num_data],\n",
    "        batch[1][:num_data].tolist(),\n",
    "    )  # get num_data of images, labels\n",
    "    plt.style.use(\"dark_background\")\n",
    "    _, axes = plt.subplots(1, num_data, figsize=figsize)\n",
    "    for n in range(num_data):\n",
    "        axes[n].set_title(labels[n])\n",
    "        imgs[n] = _denormalize(imgs[n], imagenet_stats)\n",
    "        axes[n].imshow(torch.clamp(imgs[n], 0, 1).permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876cc5e1-8b0d-4a60-b055-2a0df0f1ba10",
   "metadata": {},
   "source": [
    "# Display Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training data\")\n",
    "show_data(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89065081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test data\")\n",
    "show_data(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation data\")\n",
    "show_data(valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88aa5e-b0aa-4f64-a1c8-c16384e162de",
   "metadata": {},
   "source": [
    "# Define the Model Class\n",
    "\n",
    "### AKA DinosaurBoneFinder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinosourBoneFinder(nn.Module):\n",
    "    \"\"\"\n",
    "    A model to classify aerial images that could potentially have Jurassic fossils.\n",
    "    We are using a pretrained resnet backbone model \n",
    "    and images given to model are classified into one of 3 classes.\n",
    "    0 - no bone\n",
    "    1 - bone possible\n",
    "    2 - bone likely\n",
    "\n",
    "    \n",
    "    We currently use the resnet18 model as a backbone\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone=18, simple=False):\n",
    "        super(DinosourBoneFinder, self).__init__()\n",
    "        backbones = {\n",
    "            18: models.resnet18,\n",
    "            34: models.resnet34,\n",
    "            50: models.resnet50,\n",
    "            101: models.resnet101,\n",
    "        }\n",
    "        self.network = backbones[backbone](pretrained=True)\n",
    "        for m, p in zip(self.network.modules(), self.network.parameters()):\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                p.requires_grad = False\n",
    "        if simple:\n",
    "            self.network.fc = nn.Linear(self.network.fc.in_features, 3)\n",
    "        else:\n",
    "            self.network.fc = nn.Sequential(\n",
    "                nn.Linear(self.network.fc.in_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.6),\n",
    "                nn.Linear(256, 3),\n",
    "            )\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        return self.network(x_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"class that holds logic for calculating accuracy and printing it\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.acc = {\"train\": [], \"val\": []}\n",
    "        self.loss = {\"train\": [], \"val\": []}\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def accuracy(yhat, labels, debug):\n",
    "        \"\"\"accuracy of a batch\"\"\"\n",
    "        yhat = torch.log_softmax(yhat, dim=1)  # softmax of logit output\n",
    "        yhat = yhat.max(1)[1]  # get index of max values\n",
    "        if debug:\n",
    "            print(f\"outputs: {yhat}\")\n",
    "            print(f\"labels: {labels}\")\n",
    "        acc = yhat.eq(labels).sum() / len(yhat)\n",
    "        return acc\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"loss:\\n training set  : {self.loss['train'][-1]:.4}\\n validation set: {self.loss['val'][-1]:.4}\\n\"\n",
    "            f\"accuracy:\\n training set  : {self.acc['train'][-1]:.4}\\n validation set: {self.acc['val'][-1]:.4} \"\n",
    "        )\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"plot loss and acc curves\"\"\"\n",
    "        train_acc = [x * 100 for x in self.acc[\"train\"]]\n",
    "        val_acc = [x * 100 for x in self.acc[\"val\"]]\n",
    "        _, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 2.5))\n",
    "        ax[0].plot(self.loss[\"train\"], \"-o\")\n",
    "        ax[0].plot(self.loss[\"val\"], \"-o\")\n",
    "        ax[0].set_ylabel(\"loss\")\n",
    "        ax[0].set_title(f\"Train vs validation loss\")\n",
    "        ax[1].plot(train_acc, \"-o\")\n",
    "        ax[1].plot(val_acc, \"-o\")\n",
    "        ax[1].set_ylabel(\"accuracy (%)\")\n",
    "        ax[1].set_title(\"Training vs validation acc\")\n",
    "        for x in ax:\n",
    "            x.yaxis.grid(True)\n",
    "            x.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "            x.legend([\"train\", \"validation\"])\n",
    "            x.set_xlabel(\"epoch\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300be11-e3ae-440b-84a5-f252ac4cf8b3",
   "metadata": {},
   "source": [
    "# Define Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Trainer class that takes care of training and validation passes.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        device=\"cpu\",\n",
    "        optimizer=torch.optim.SGD,\n",
    "        epochs=10,\n",
    "        lr=0.05,\n",
    "        ipx=False,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.ipx = ipx\n",
    "        self.epochs = epochs\n",
    "        self.metrics = Metrics()\n",
    "        self.lr = lr\n",
    "        if isinstance(optimizer, torch.optim.Adam):\n",
    "            self.lr = 2e-3\n",
    "        self.optimizer = optimizer(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def forward_pass(self, inputs, labels, debug=False):\n",
    "        \"\"\"Perform forward pass of models with `inputs`,\n",
    "        calculate loss and accuracy and return it.\n",
    "        \"\"\"\n",
    "        outputs = self.model(inputs)  # forward pass model\n",
    "        loss = self.loss_fn(outputs, labels)  # calculate loss\n",
    "        acc = self.metrics.accuracy(outputs, labels, debug=debug)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_one_batch(self, max_epoch=100):\n",
    "        \"\"\"Train the model using just one batch for max_epoch.\n",
    "        use this function to debug the training loop\"\"\"\n",
    "        self.model.train()\n",
    "        inputs, labels = next(iter(self.train_dataloader))\n",
    "        for epoch in range(max_epoch):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()  # zero gradients\n",
    "            loss, _ = self.forward_pass(inputs, labels, debug=True)\n",
    "            loss.backward()  # calculate gradients\n",
    "            self.optimizer.step()  # update params\n",
    "            print(\n",
    "                f\"[Epoch: {epoch+1}]\\\n",
    "                    \\n loss: {loss.item()/len(self.train_dataloader):.4f}\"\n",
    "            )\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training loop, return epoch loss and accuracy.\"\"\"\n",
    "        self.model.train()\n",
    "        t_epoch_loss, t_epoch_acc = 0.0, 0.0\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=\"tr loop\"):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            if self.ipx:\n",
    "                inputs = inputs.to(memory_format=torch.channels_last)\n",
    "            self.optimizer.zero_grad()  # zero gradients\n",
    "            loss, acc = self.forward_pass(inputs, labels)  # forward pass\n",
    "            loss.backward()  # backward\n",
    "            self.optimizer.step()  # update gradients\n",
    "            t_epoch_loss += loss.item()\n",
    "            t_epoch_acc += acc.item()\n",
    "        return (t_epoch_loss, t_epoch_acc)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        \"\"\"Validation loop, return validation epoch loss and accuracy.\"\"\"\n",
    "        self.model.eval()\n",
    "        v_epoch_loss, v_epoch_acc = 0.0, 0.0\n",
    "        for inputs, labels in tqdm(self.valid_dataloader, desc=\"ev loop\"):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            loss, acc = self.forward_pass(inputs, labels)\n",
    "            v_epoch_loss += loss.item()\n",
    "            v_epoch_acc += acc.item()\n",
    "        return (v_epoch_loss, v_epoch_acc)\n",
    "\n",
    "    def _to_ipx(self):\n",
    "        \"\"\"convert model memory format to channels_last to IPEX format.\"\"\"\n",
    "        self.model.train()\n",
    "        self.model = self.model.to(memory_format=torch.channels_last)\n",
    "        self.model, self.optimizer = ipex.optimize(\n",
    "            self.model, optimizer=self.optimizer, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def fine_tune(self, train_dataloader, valid_dataloader, debug=False):\n",
    "        \"\"\"Fine tune `self.model` using training set and measure perf using\n",
    "        training and validation set.\n",
    "\n",
    "        `debug`: if True, will run train_one_batch function with one batch\n",
    "        of train_dataloader to see if we can overfit the model, used to debug\n",
    "        the training loop.\n",
    "\n",
    "        `train_dataloader`: training set\n",
    "        `valid_dataloader`: validation set\n",
    "        \"\"\"\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        if debug:\n",
    "            self.train_one_batch()\n",
    "        else:\n",
    "            time_per_epoch = []\n",
    "            if self.ipx:\n",
    "                self._to_ipx()\n",
    "            print(f\"fine tuning model for max epochs: {self.epochs}\")\n",
    "            for epoch in range(self.epochs):\n",
    "                print(f\"Epoch: [{epoch+1}]\")\n",
    "                st_time = time.perf_counter()\n",
    "                t_epoch_loss, t_epoch_acc = self.train()\n",
    "                fn_time = time.perf_counter()\n",
    "                time_per_epoch.append(fn_time - st_time)\n",
    "                v_epoch_loss, v_epoch_acc = self.validate()\n",
    "                self.metrics.loss[\"train\"].append(t_epoch_loss / len(train_dataloader))\n",
    "                self.metrics.loss[\"val\"].append(v_epoch_loss / len(valid_dataloader))\n",
    "                self.metrics.acc[\"train\"].append(t_epoch_acc / len(train_dataloader))\n",
    "                self.metrics.acc[\"val\"].append(v_epoch_acc / len(valid_dataloader))\n",
    "                print(self.metrics)\n",
    "            return time_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a30e4e-1e97-4336-8162-6269d28ffd50",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd151fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DinosourBoneFinder()  # init model\n",
    "trainer = Trainer(model, epochs=6, ipx=True)  # set up trainer with the model\n",
    "tft = trainer.fine_tune(train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48061a-649c-41d8-bec1-e14fd68d7a79",
   "metadata": {},
   "source": [
    "# Compare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e460dd-49eb-42b7-a435-a1439cf9af24",
   "metadata": {},
   "source": [
    "# Save the model \n",
    "\n",
    "Save it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f49b8-a25d-481d-948e-05ef46628cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'resnet18_3Class_RN'\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(f'models/{modelName}.pt') # Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fdbef-93e8-4660-857a-6b4c2c6b132f",
   "metadata": {},
   "source": [
    "# Load a Saved Model\n",
    "\n",
    "Use this to load a previously created model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965f1e1-b04c-41d2-9441-1b5a0a3467f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'resnet18_3Class_RN'\n",
    "modelRead = torch.jit.load(f'models/{modelName}.pt')\n",
    "modelRead.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cca1f5-7175-41f7-94ea-50c299176d81",
   "metadata": {},
   "source": [
    "# Infer Function\n",
    "\n",
    "Used to score and get associated filename for each scored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92ad1f-f331-4319-a42f-2483a8dc3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose \n",
    "    labels have to be predicted are kept.\n",
    "    \n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        yhat = model(imgs)\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "    return images, yhats, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ad634-b1b5-456b-a47c-9a7b30de7ddb",
   "metadata": {},
   "source": [
    "## Using Infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228abb78-54e6-4231-b1f8-77826271f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir  data/ThreeClassManualRemove0s/test\n",
    "!mkdir  data/ThreeClassManualRemove0s/test/unknown\n",
    "!cp data/DinosaurNationalMonument/20220514/224/*.jpg data/ThreeClassManualRemove0s/test/unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebabad9-84cb-4dfe-ac4f-b63b4e76739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, yhats, img_paths = infer(model, data_path=\"./data/ThreeClassManualRemove0s/test/\")\n",
    "# infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "# print(\"infered images with labels\")\n",
    "# show_data(infer_dataloader, imagenet_stats, 10, figsize=(20, 8))\n",
    "\n",
    "input_size = 224\n",
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "images, yhats, img_paths = infer(modelRead, data_path=\"./data/ThreeClassManualRemove0s/test/\")\n",
    "infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "print(\"infered images with labels\")\n",
    "show_data(infer_dataloader, imagenet_stats, 10, figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212a7750-c224-45df-b4c0-911c0179ac3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43myhats\u001b[49m, img_paths))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yhats' is not defined"
     ]
    }
   ],
   "source": [
    "list(zip(yhats, img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2655e94-dd4a-4193-8ff5-09bf4df08a89",
   "metadata": {},
   "source": [
    "If you have any issues or want to contribute, please contact our authors:\n",
    "Intel oneAPI Solution Architect\n",
    "- Unnikrishnan Nair, Rahul [rahul.unnikrishnan.nair (at) intel.com]\n",
    "- Chesebrough, Bob [bob.chesebrough (at) intel.com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2a3d7-9648-4862-8ebc-0dae52ecb983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1733b34285ed74833bcb8e1b7a940727029b0435f34e09e572d05f37d583a466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
