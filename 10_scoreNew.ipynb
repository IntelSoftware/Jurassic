{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa18f0-4319-4d8a-9275-d147bc0a6991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d53e-30c5-49c6-9c8b-173a6ae048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e456-a8b0-45c5-9991-ff74ea0a5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18_3Class_RN_FT_True_Epochs30\"\n",
    "model_read = torch.jit.load(f\"models/{model_name}.pt\")\n",
    "\n",
    "# model_name = \"resnet18_3ClassNewZeros\"\n",
    "# model_read = torch.jit.load(f\"models/{model_name}.pt\")\n",
    "\n",
    "# model_name = \"resnet18-Gold20220530.full\"\n",
    "# model_read = torch.load(f\"models/{model_name}.pt\")\n",
    "\n",
    "model_read.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44ef35-ffa1-4eb4-a6b7-e7bde0cd1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"custom ImageFolder to get the filepaths along with the image and label data.\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose\n",
    "    labels have to be predicted are kept.\n",
    "\n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "\n",
    "    returns: (\n",
    "        images: images loaded from disk for inferece,\n",
    "        yhats: predicted labels\n",
    "        paths: image file-path on disk        )\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        yhat = model(imgs)\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "    return images, yhats, paths\n",
    "\n",
    "def show_data(dataloader, imagenet_stats=imagenet_stats, num_data=4, figsize=(10, 6)):\n",
    "    \"\"\"show `num_data` of images and labels from dataloader.\"\"\"\n",
    "    batch = next(iter(dataloader))  # batch of with images, batch of labels\n",
    "    imgs, labels = (\n",
    "        batch[0][:num_data],\n",
    "        batch[1][:num_data].tolist(),\n",
    "    )  # get num_data of images, labels\n",
    "    plt.style.use(\"dark_background\")\n",
    "    _, axes = plt.subplots(1, num_data, figsize=figsize)\n",
    "    for n in range(num_data):\n",
    "        axes[n].set_title(labels[n])\n",
    "        imgs[n] = _denormalize(imgs[n], imagenet_stats)\n",
    "        axes[n].imshow(torch.clamp(imgs[n], 0, 1).permute(1, 2, 0))\n",
    "\n",
    "def _denormalize(images, imagenet_stats):\n",
    "    \"\"\"de normalize dataset using imagenet std and mean to show images\"\"\"\n",
    "    mean = torch.tensor(imagenet_stats[0]).reshape(1, 3, 1, 1)\n",
    "    std = torch.tensor(imagenet_stats[1]).reshape(1, 3, 1, 1)\n",
    "    return images * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb9840-d28a-4f62-a16e-62513576bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/ThreeClassManualRemove0s/test\n",
    "!mkdir  data/ThreeClassManualRemove0s/test/unknown\n",
    "!cp data/DinosaurNationalMonument/20220514/224/*.jpg data/ThreeClassManualRemove0s/test/unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6b8e2-90a0-416e-ac73-f0c755099072",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "images, yhats, img_paths = infer(\n",
    "    model_read, data_path=\"./data/ThreeClassManualRemove0s/test/\"\n",
    ")\n",
    "infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "print(\"infered images with labels\")\n",
    "show_data(infer_dataloader, imagenet_stats, 20, figsize=(20, 16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111421d-cd6e-4cc7-b0bd-576f7ecbb21f",
   "metadata": {},
   "source": [
    "# Inference Given Large Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5adea7a-6963-4c42-b43f-2ce55ea5a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from os.path import exists\n",
    "import os\n",
    "path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "#path = \"data/Explore/Pombal01.PNG\"\n",
    "\n",
    "img = Image.open(path).convert('RGB')\n",
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd4d75-ef40-4c55-96bd-91d3f9e1206a",
   "metadata": {},
   "source": [
    "# Get sample near DNM Excavation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c91fa2-7928-4bf5-9922-1a0b3090ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left = 4*224+112\n",
    "# low = 4*224+112\n",
    "left = 2*224\n",
    "low = 1*224\n",
    "bbox = (left, low, left + 224, low + 224)\n",
    "working_slice = img.crop(bbox)\n",
    "working_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6b2a3-ccdb-43a9-8c40-e26457ffc40a",
   "metadata": {},
   "source": [
    "# Get sample at DNM near top of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae8824-7c17-450b-85ce-5151fd9a3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = 4*224+112\n",
    "low = 0*224+112\n",
    "bbox = (left, low, left + 224, low + 224)\n",
    "working_slice = img.crop(bbox)\n",
    "working_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3d10a-e7af-48ff-a4b3-3a1c0c4995d6",
   "metadata": {},
   "source": [
    "# Simple eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836302a0-e03d-4ee0-9953-4259dc723251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def transform_image(image):\n",
    "    my_transforms = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(\n",
    "                                            [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])])\n",
    "    return my_transforms(image).unsqueeze(0)\n",
    "\n",
    "def eval_simple(working_slice):\n",
    "#     x = TF.to_tensor(working_slice)\n",
    "#     x.unsqueeze_(0)\n",
    "    x = transform_image(working_slice)\n",
    "    output = model_read(x)\n",
    "#     print(torch.softmax(output,1).detach().numpy().flatten())\n",
    "#     print(output.detach().numpy().flatten())\n",
    "    return output.detach().numpy().argmax()\n",
    "\n",
    "eval_simple(working_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53009f4-b70a-4752-811c-df810354eb22",
   "metadata": {},
   "source": [
    "# Score large map of DNM\n",
    "\n",
    "<img src=\"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16761e-75a1-460d-949a-a1a0777b30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from os.path import exists\n",
    "import os\n",
    "#path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "#path = \"data/Test/GreenColorado.jpg\"\n",
    "#path = \"data/Test/NMMystery1.jpg\"\n",
    "#path = \"data/Test/MoabMillCreek.jpg\"\n",
    "img = Image.open(path).convert('RGB')\n",
    "\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "countBuf = np.ones( (img.size[0], img.size[1]) )\n",
    "sumBuf =   np.zeros( (img.size[0], img.size[1]) )\n",
    "\n",
    "start = time.time()\n",
    "step = 8  # choose a factor of 224: 1, 2, 4, 7, 8, 14, 16, 28, 32, 56, 112, and 224. Small is smooth map, large is fast\n",
    "counts = {0:0, 1:0, 2:0}\n",
    "scale = {0:0, 1:1, 2:1}\n",
    "for x in tqdm(range(0, img.size[0]-224, step)):\n",
    "    for y in range(0, img.size[1]-224, step):  \n",
    "        bbox = (x, y, x + 224, y + 224)\n",
    "        working_slice = img.crop(bbox)\n",
    "        countBuf[bbox[0]:bbox[2], bbox[1]:bbox[3]] += 1\n",
    "        sumBuf[bbox[0]:bbox[2], bbox[1]:bbox[3]] += scale[eval_simple(working_slice)]\n",
    "print(f\"step size = {step}, Elapsed: {(time.time() - start):6.1f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365d563-bb10-46c1-bd44-04ffa8aaeb88",
   "metadata": {},
   "source": [
    "# Compute the mean of scores for sliding tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae35ef3-fe56-430d-813f-878c547c5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set opacity to 159: 0 is transparent, 255 is opaque\n",
    "meanBuf = sumBuf/countBuf\n",
    "mat = np.uint8(meanBuf.T*159/meanBuf.max()) # scale the opacity: 0 transpartent, 255 solid\n",
    "idx = mat < 0\n",
    "mat[idx] = 0\n",
    "output = Image.fromarray(mat)\n",
    "output.save('results/bobTile.png')\n",
    "np.save('results/meanBuf.npy', mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2396f5-ebc4-4a36-82c6-61fd27830d6b",
   "metadata": {},
   "source": [
    "# NumPy Select: Color threshold differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32929b10-2493-4792-abd4-aa9fa874bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "#path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "\n",
    "img = Image.open(path)\n",
    "alpha = np.uint8(meanBuf.T*159/meanBuf.max())\n",
    "# lo = 60\n",
    "# hi = 120\n",
    "# condition = [ (alpha  < lo) ,\n",
    "#               ( alpha >= lo) & (alpha < hi)]\n",
    "# choice = [ 0, \n",
    "#            64 ]\n",
    "# default = [(128)]\n",
    "\n",
    "lo = 60\n",
    "hi = 120\n",
    "condition = [ (alpha  < lo) ,\n",
    "              ( alpha >= lo) & (alpha < hi)]\n",
    "choice = [ 0, \n",
    "           64 ]\n",
    "default = [(128)]\n",
    "\n",
    "newAlpha = np.select(condition, choice, default= default )\n",
    "mask = Image.fromarray(newAlpha.astype('uint8'))\n",
    "green = Image.new('RGBA',meanBuf.shape,(0,255,0,255))\n",
    "img.paste(green, (0, 0), mask)\n",
    "img.save('results/bobNewMapSelect.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246745ef-6357-4030-82a3-ca770928a84a",
   "metadata": {},
   "source": [
    "# Heatmap Approach\n",
    "\n",
    "Color Legend:\n",
    "- Bright Red: Bones more likely\n",
    "- Bright Blue: Bone not likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f5e23-bd0f-4e32-ac3b-c0b14c115c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(path)\n",
    "alpha = np.load('results/meanBuf.npy')\n",
    "\n",
    "imgcv = Image.open(path.replace('.jpg','.PNG'))\n",
    "heatmap_img = np.copy(imgcv)\n",
    "alpha1D = alpha/alpha.max()*255\n",
    "\n",
    "heatmap_img[:,:,0] = alpha1D\n",
    "heatmap_img[:,:,1] = 255 - alpha1D\n",
    "heatmap_img[:,:,2] = 255 - alpha1D\n",
    "\n",
    "opacity = .5\n",
    "imgHeat = Image.blend(Image.fromarray(heatmap_img), imgcv, alpha=0.5)\n",
    "imgHeat.save('results/HeatMap.png')\n",
    "imgHeat.show()\n",
    "print(\"Color Legend:\\n- Red: Higher Probability\\n- Blue: -Lower Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500f665-21dc-450e-95d3-66d0cc812d15",
   "metadata": {},
   "source": [
    "## Notices and Disclaimers\n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "\n",
    "No product or component can be absolutely secure. \n",
    "\n",
    "Your costs and results may vary. \n",
    "\n",
    "© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dcd37-4e5f-4331-ad10-0408523c22f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
