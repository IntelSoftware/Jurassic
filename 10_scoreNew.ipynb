{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d53e-30c5-49c6-9c8b-173a6ae048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e456-a8b0-45c5-9991-ff74ea0a5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18_3Class_RN\"\n",
    "model_read = torch.jit.load(f\"models/{model_name}.pt\")\n",
    "model_read.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44ef35-ffa1-4eb4-a6b7-e7bde0cd1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"custom ImageFolder to get the filepaths along with the image and label data.\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose\n",
    "    labels have to be predicted are kept.\n",
    "\n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "\n",
    "    returns: (\n",
    "        images: images loaded from disk for inferece,\n",
    "        yhats: predicted labels\n",
    "        paths: image file-path on disk        )\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        yhat = model(imgs)\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "    return images, yhats, paths\n",
    "\n",
    "def show_data(dataloader, imagenet_stats=imagenet_stats, num_data=4, figsize=(10, 6)):\n",
    "    \"\"\"show `num_data` of images and labels from dataloader.\"\"\"\n",
    "    batch = next(iter(dataloader))  # batch of with images, batch of labels\n",
    "    imgs, labels = (\n",
    "        batch[0][:num_data],\n",
    "        batch[1][:num_data].tolist(),\n",
    "    )  # get num_data of images, labels\n",
    "    plt.style.use(\"dark_background\")\n",
    "    _, axes = plt.subplots(1, num_data, figsize=figsize)\n",
    "    for n in range(num_data):\n",
    "        axes[n].set_title(labels[n])\n",
    "        imgs[n] = _denormalize(imgs[n], imagenet_stats)\n",
    "        axes[n].imshow(torch.clamp(imgs[n], 0, 1).permute(1, 2, 0))\n",
    "\n",
    "def _denormalize(images, imagenet_stats):\n",
    "    \"\"\"de normalize dataset using imagenet std and mean to show images\"\"\"\n",
    "    mean = torch.tensor(imagenet_stats[0]).reshape(1, 3, 1, 1)\n",
    "    std = torch.tensor(imagenet_stats[1]).reshape(1, 3, 1, 1)\n",
    "    return images * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb9840-d28a-4f62-a16e-62513576bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/ThreeClassManualRemove0s/test\n",
    "!mkdir  data/ThreeClassManualRemove0s/test/unknown\n",
    "!cp data/DinosaurNationalMonument/20220514/224/*.jpg data/ThreeClassManualRemove0s/test/unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6b8e2-90a0-416e-ac73-f0c755099072",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "images, yhats, img_paths = infer(\n",
    "    model_read, data_path=\"./data/ThreeClassManualRemove0s/test/\"\n",
    ")\n",
    "infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "print(\"infered images with labels\")\n",
    "show_data(infer_dataloader, imagenet_stats, 10, figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783c198-770b-4c22-83ce-fdabb27abfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d5f52-b5f8-4b85-a489-accb5700d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from os.path import exists\n",
    "import os\n",
    "\n",
    "#path = 'data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png'\n",
    "path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "img = Image.open(path)\n",
    "# for x in range(img.size[0]//224):\n",
    "#     for y in range(img.size[1]//224):\n",
    "#         left = x * 224\n",
    "#         low = y * 224\n",
    "#         bbox = (left, low, left + 224, low + 224)\n",
    "#         working_slice = img.crop(bbox)\n",
    "#         filename = '{}/224/DNMx{:02d}y{:02d}.png'.format(folder, x, y)\n",
    "#         print(filename)\n",
    "#         working_slice.save(filename)\n",
    "#         # remove partial images\n",
    "#         r, g, b = working_slice.convert('RGB').split()\n",
    "#         if g.histogram()[0] + r.histogram()[0] + b.histogram()[0] > 223*3:\n",
    "#             print(fn,\" remove: has black stripe\")\n",
    "#             os.remove(fn, dir_fd=None)\n",
    "#         working_slice.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5adea7a-6963-4c42-b43f-2ce55ea5a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "img = Image.open(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c91fa2-7928-4bf5-9922-1a0b3090ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = 4*224+112\n",
    "low = 4*224+112\n",
    "bbox = (left, low, left + 224, low + 224)\n",
    "working_slice = img.crop(bbox)\n",
    "working_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae8824-7c17-450b-85ce-5151fd9a3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = 4*224+112\n",
    "low = 0*224+112\n",
    "bbox = (left, low, left + 224, low + 224)\n",
    "working_slice = img.crop(bbox)\n",
    "working_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836302a0-e03d-4ee0-9953-4259dc723251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "left = 4*224\n",
    "low = 4*224\n",
    "bbox = (left, low, left + 224, low + 224)\n",
    "working_slice = img.crop(bbox)\n",
    "working_slice\n",
    "\n",
    "def eval_simple(working_slice):\n",
    "    x = TF.to_tensor(working_slice)\n",
    "    x.unsqueeze_(0)\n",
    "    output = model_read(x)\n",
    "    return output.detach().numpy().argmax()\n",
    "\n",
    "eval_simple(working_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748c32b-90ff-4dab-a4ab-2125bbf9e412",
   "metadata": {},
   "source": [
    "# Convert to PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2da3b-42c1-48e3-bff1-d2e3ca831e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #sum[300:524, 600:824] = 255\n",
    "# #Image.fromarray(sum)\n",
    "# bbox = (500, 700, 500+224, 700+224)\n",
    "# sumBuf[bbox[0]:bbox[1], bbox[2]:bbox[3]] =129\n",
    "# Image.fromarray(sumBuf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53009f4-b70a-4752-811c-df810354eb22",
   "metadata": {},
   "source": [
    "# Score large map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16761e-75a1-460d-949a-a1a0777b30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "countBuf = np.ones( (img.size[0], img.size[1]) )\n",
    "sumBuf =   np.zeros( (img.size[0], img.size[1]) )\n",
    "\n",
    "start = time.time()\n",
    "step = 8\n",
    "counts = {0:0, 1:0, 2:0}\n",
    "#scale = {0:-10, 1:0, 2:10}\n",
    "for x in tqdm(range(0, img.size[0]-224, step)):\n",
    "    for y in range(0, img.size[1]-224, step):  \n",
    "        bbox = (x, y, x + 224, y + 224)\n",
    "        working_slice = img.crop(bbox)\n",
    "        countBuf[bbox[0]:bbox[2], bbox[1]:bbox[3]] += 1\n",
    "        sumBuf[bbox[0]:bbox[2], bbox[1]:bbox[3]] += eval_simple(working_slice)\n",
    "        counts[eval_simple(working_slice)] += 1\n",
    "        #print(x, y, eval_simple(working_slice))\n",
    "print(f\"step size = {step}, Elapsed: {(time.time() - start):6.1f} sec\")\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae35ef3-fe56-430d-813f-878c547c5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanBuf = sumBuf/countBuf\n",
    "output = Image.fromarray(np.uint8(meanBuf.T*159/meanBuf.max()))\n",
    "output.save('data/bobTile.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b7e76-b9dd-4c40-967b-d587346f2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "img = Image.open(path)\n",
    "green = Image.new('RGBA',meanBuf.shape,(0,255,0,255))\n",
    "alpha = np.uint8(meanBuf.T*159/meanBuf.max())\n",
    "#green.putalpha(alpha)\n",
    "mask = Image.fromarray(alpha)\n",
    "img.paste(green, (0, 0), mask)\n",
    "img.save('data/bobNewMap.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d86d8a-5e16-4825-b2c3-ef58d020f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(alpha, bins=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32929b10-2493-4792-abd4-aa9fa874bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/DinosaurNationalMonument/Dinosaur National Monument Panorama.png\"\n",
    "img = Image.open(path)\n",
    "condition = [ (alpha  < 65) ,\n",
    "              ( alpha >= 65) & (alpha < 100)]\n",
    "choice = [ 0, \n",
    "           64 ]\n",
    "default = [(128)]\n",
    "newAlpha = np.select(condition, choice, default= default )\n",
    "\n",
    "mask = Image.fromarray(newAlpha.astype('uint8'))\n",
    "img.paste(green, (0, 0), mask)\n",
    "img.save('data/bobNewMapSelect.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549f8c4-e7ce-44a5-bcad-e5cb04c71fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f27a4f-b070-4adb-9371-c771606c3930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
