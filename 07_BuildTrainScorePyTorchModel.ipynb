{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d9ae70-0700-444d-b057-7f474dbb0876",
   "metadata": {},
   "source": [
    "## Build, Train & Score Model with PyTorch\n",
    "\n",
    "### Introduction: Rahul Nair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41264b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "%pip install tqdm\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0c4b5-7a15-4177-a5c0-a8e3218fcb6f",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef53d2c-5c27-4bc0-80e5-e622ea6f3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febceda-0e2a-4d85-b368-3d4916e09879",
   "metadata": {},
   "source": [
    "## Print Software Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"ipex version: {ipex.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55612962-55d6-44e1-bb9b-8477750b2e66",
   "metadata": {},
   "source": [
    "## Define Utility Functions\n",
    "\n",
    "### seed_everything and set_env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 4242):\n",
    "    \"\"\"set all random seeds using `seed`\"\"\"\n",
    "    print(f\"seed set to: {seed}\")\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def set_env_vars() -> int:\n",
    "    \"\"\"set openMP and torch params\"\"\"\n",
    "    num_physical_cores = psutil.cpu_count(logical=False)\n",
    "    print(f\"setting omp num threads: {num_physical_cores}\")\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(num_physical_cores)\n",
    "    os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,compact,1,0\"\n",
    "    os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "    return num_physical_cores\n",
    "\n",
    "\n",
    "seed_everything(9342)\n",
    "num_physical_cores = set_env_vars()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457215f-9c4e-42c8-b45c-edc473dd0dfe",
   "metadata": {},
   "source": [
    "## Define dataset transforms for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, validation  dataset transforms\n",
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "img_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomApply(\n",
    "                [transforms.GaussianBlur(kernel_size=(1, 3), sigma=(1, 3))], p=0.2\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(180),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*imagenet_stats),\n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df446f6f-5bc1-4679-96b4-4bf169150a80",
   "metadata": {},
   "source": [
    "## Create dataset for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa503e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for Training and Validation\n",
    "num_physical_cores = psutil.cpu_count(logical=False)\n",
    "data_dir = pathlib.Path(\"./data/ThreeClassManualRemove0s/\")\n",
    "TRAIN_DIR = data_dir / \"train\"\n",
    "VALID_DIR = data_dir / \"val\"\n",
    "\n",
    "# no image transforms for validation data\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=img_transforms[\"train\"])\n",
    "valid_data = datasets.ImageFolder(VALID_DIR, transform=img_transforms[\"valid\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e53288-526c-405f-bb7d-330813afd921",
   "metadata": {},
   "source": [
    "## Define Utility Functions to visualize class distributions\n",
    "\n",
    "### data_distribution and plot_data_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distribution(dataset=train_data, path: str = TRAIN_DIR) -> dict:\n",
    "    \"\"\"return dict of data distribtion of each class.\"\"\"\n",
    "    cls_count = dict.fromkeys(dataset.class_to_idx, 0)\n",
    "    for cls in cls_count.keys():\n",
    "        cls_count[cls] = len(fnmatch.filter(os.listdir(f\"{path}/{cls}\"), \"*.png\"))\n",
    "    return cls_count\n",
    "\n",
    "\n",
    "def plot_data_distribution(data_dist: dict, title: str = \"\"):\n",
    "    \"\"\"plot data distribution\"\"\"\n",
    "    cls, count = list(data_dist.keys()), list(data_dist.values())\n",
    "    p = sns.barplot(x=cls, y=count)\n",
    "    p.set_title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73fa45-ebf8-4eb0-bc89-9cffca812284",
   "metadata": {},
   "source": [
    "# Plot Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cda558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dist = data_distribution(train_data, path=TRAIN_DIR)\n",
    "plot_data_distribution(train_data_dist, \"train_data_dist\")\n",
    "print(f\"train data dist: {train_data_dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_dist = data_distribution(valid_data, path=VALID_DIR)\n",
    "plot_data_distribution(valid_data_dist, \"valid_data_dist\")\n",
    "print(f\"valid data dist: {valid_data_dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size)\n",
    "print(f\"batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b12237-bff8-470c-9ab1-ab85b7926036",
   "metadata": {},
   "source": [
    "## Define Utility Functions to display data from dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _denormalize(images, imagenet_stats):\n",
    "    \"\"\"de normalize dataset using imagenet std and mean to show images\"\"\"\n",
    "    mean = torch.tensor(imagenet_stats[0]).reshape(1, 3, 1, 1)\n",
    "    std = torch.tensor(imagenet_stats[1]).reshape(1, 3, 1, 1)\n",
    "    return images * std + mean\n",
    "\n",
    "\n",
    "def show_data(dataloader, imagenet_stats=imagenet_stats, num_data=4, figsize=(10, 6)):\n",
    "    \"\"\"show `num_data` of images and labels from dataloader.\"\"\"\n",
    "    batch = next(iter(dataloader))  # batch of with images, batch of labels\n",
    "    imgs, labels = (\n",
    "        batch[0][:num_data],\n",
    "        batch[1][:num_data].tolist(),\n",
    "    )  # get num_data of images, labels\n",
    "    plt.style.use(\"dark_background\")\n",
    "    _, axes = plt.subplots(1, num_data, figsize=figsize)\n",
    "    for n in range(num_data):\n",
    "        axes[n].set_title(labels[n])\n",
    "        imgs[n] = _denormalize(imgs[n], imagenet_stats)\n",
    "        axes[n].imshow(torch.clamp(imgs[n], 0, 1).permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876cc5e1-8b0d-4a60-b055-2a0df0f1ba10",
   "metadata": {},
   "source": [
    "## Display Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training data\")\n",
    "show_data(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation data\")\n",
    "show_data(valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88aa5e-b0aa-4f64-a1c8-c16384e162de",
   "metadata": {},
   "source": [
    "## Define the Model Class\n",
    "    Our model is a Resnet18 based 3 class classification Deep Neural Network\n",
    "\n",
    "### AKA DinosaurBoneFinder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinosourBoneFinder(nn.Module):\n",
    "    \"\"\"\n",
    "    A model to classify aerial images that could potentially have Jurassic fossils.\n",
    "    We are using a pretrained resnet backbone model\n",
    "    and images given to model are classified into one of 3 classes.\n",
    "    0 - no bone\n",
    "    1 - bone possible\n",
    "    2 - bone likely\n",
    "\n",
    "\n",
    "    We currently use the resnet18 model as a backbone\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone=18, simple=False):\n",
    "        super(DinosourBoneFinder, self).__init__()\n",
    "        backbones = {\n",
    "            18: models.resnet18,\n",
    "            34: models.resnet34,\n",
    "            50: models.resnet50,\n",
    "            101: models.resnet101,\n",
    "        }\n",
    "        self.network = backbones[backbone](pretrained=True)\n",
    "        for m, p in zip(self.network.modules(), self.network.parameters()):\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                p.requires_grad = False\n",
    "        if simple:\n",
    "            self.network.fc = nn.Linear(self.network.fc.in_features, 3)\n",
    "        else:\n",
    "            self.network.fc = nn.Sequential(\n",
    "                nn.Linear(self.network.fc.in_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.6),\n",
    "                nn.Linear(\n",
    "                    256, 3\n",
    "                ),  # here we are using 3 for `out_features` as the image given\n",
    "                # to the model can be one of 3 classes (0 - no bone, 1 - bone possible, 2 - bone likely)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        return self.network(x_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666bcbfd",
   "metadata": {},
   "source": [
    "## Define Metrics - Utility class to measure accuracy of the model and plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"class that holds logic for calculating accuracy and printing it\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.acc = {\"train\": [], \"val\": []}\n",
    "        self.loss = {\"train\": [], \"val\": []}\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def accuracy(yhat, labels, debug):\n",
    "        \"\"\"accuracy of a batch\"\"\"\n",
    "        yhat = torch.log_softmax(yhat, dim=1)  # softmax of logit output\n",
    "        yhat = yhat.max(1)[1]  # get index of max values\n",
    "        if debug:\n",
    "            print(f\"outputs: {yhat}\")\n",
    "            print(f\"labels: {labels}\")\n",
    "        acc = yhat.eq(labels).sum() / len(yhat)\n",
    "        return acc\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"loss:\\n training set  : {self.loss['train'][-1]:.4}\\n validation set: {self.loss['val'][-1]:.4}\\n\"\n",
    "            f\"accuracy:\\n training set  : {self.acc['train'][-1]:.4}\\n validation set: {self.acc['val'][-1]:.4} \"\n",
    "        )\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"plot loss and acc curves\"\"\"\n",
    "        train_acc = [x * 100 for x in self.acc[\"train\"]]\n",
    "        val_acc = [x * 100 for x in self.acc[\"val\"]]\n",
    "        _, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 2.5))\n",
    "        ax[0].plot(self.loss[\"train\"], \"-o\")\n",
    "        ax[0].plot(self.loss[\"val\"], \"-o\")\n",
    "        ax[0].set_ylabel(\"loss\")\n",
    "        ax[0].set_title(f\"Train vs validation loss\")\n",
    "        ax[1].plot(train_acc, \"-o\")\n",
    "        ax[1].plot(val_acc, \"-o\")\n",
    "        ax[1].set_ylabel(\"accuracy (%)\")\n",
    "        ax[1].set_title(\"Training vs validation acc\")\n",
    "        for x in ax:\n",
    "            x.yaxis.grid(True)\n",
    "            x.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "            x.legend([\"train\", \"validation\"])\n",
    "            x.set_xlabel(\"epoch\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300be11-e3ae-440b-84a5-f252ac4cf8b3",
   "metadata": {},
   "source": [
    "# Define Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Trainer class that takes care of training and validation passes.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        device=\"cpu\",\n",
    "        optimizer=torch.optim.SGD,\n",
    "        epochs=10,\n",
    "        lr=0.05,\n",
    "        ipx=False,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.ipx = ipx\n",
    "        self.epochs = epochs\n",
    "        self.metrics = Metrics()\n",
    "        self.lr = lr\n",
    "        if isinstance(optimizer, torch.optim.Adam):\n",
    "            self.lr = 2e-3\n",
    "        self.optimizer = optimizer(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def forward_pass(self, inputs, labels, debug=False):\n",
    "        \"\"\"Perform forward pass of models with `inputs`,\n",
    "        calculate loss and accuracy and return it.\n",
    "        \"\"\"\n",
    "        outputs = self.model(inputs)  # forward pass model\n",
    "        loss = self.loss_fn(outputs, labels)  # calculate loss\n",
    "        acc = self.metrics.accuracy(outputs, labels, debug=debug)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_one_batch(self, max_epoch=100):\n",
    "        \"\"\"Train the model using just one batch for max_epoch.\n",
    "        use this function to debug the training loop\"\"\"\n",
    "        self.model.train()\n",
    "        inputs, labels = next(iter(self.train_dataloader))\n",
    "        for epoch in range(max_epoch):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()  # zero gradients\n",
    "            loss, _ = self.forward_pass(inputs, labels, debug=True)\n",
    "            loss.backward()  # calculate gradients\n",
    "            self.optimizer.step()  # update params\n",
    "            print(\n",
    "                f\"[Epoch: {epoch+1}]\\\n",
    "                    \\n loss: {loss.item()/len(self.train_dataloader):.4f}\"\n",
    "            )\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training loop, return epoch loss and accuracy.\"\"\"\n",
    "        self.model.train()\n",
    "        t_epoch_loss, t_epoch_acc = 0.0, 0.0\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=\"tr loop\"):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            if self.ipx:\n",
    "                inputs = inputs.to(memory_format=torch.channels_last)\n",
    "            self.optimizer.zero_grad()  # zero gradients\n",
    "            loss, acc = self.forward_pass(inputs, labels)  # forward pass\n",
    "            loss.backward()  # backward\n",
    "            self.optimizer.step()  # update gradients\n",
    "            t_epoch_loss += loss.item()\n",
    "            t_epoch_acc += acc.item()\n",
    "        return (t_epoch_loss, t_epoch_acc)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        \"\"\"Validation loop, return validation epoch loss and accuracy.\"\"\"\n",
    "        self.model.eval()\n",
    "        v_epoch_loss, v_epoch_acc = 0.0, 0.0\n",
    "        for inputs, labels in tqdm(self.valid_dataloader, desc=\"ev loop\"):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            loss, acc = self.forward_pass(inputs, labels)\n",
    "            v_epoch_loss += loss.item()\n",
    "            v_epoch_acc += acc.item()\n",
    "        return (v_epoch_loss, v_epoch_acc)\n",
    "\n",
    "    def _to_ipx(self):\n",
    "        \"\"\"convert model memory format to channels_last to IPEX format.\"\"\"\n",
    "        self.model.train()\n",
    "        self.model = self.model.to(memory_format=torch.channels_last)\n",
    "        self.model, self.optimizer = ipex.optimize(\n",
    "            self.model, optimizer=self.optimizer, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def fine_tune(self, train_dataloader, valid_dataloader, debug=False):\n",
    "        \"\"\"Fine tune `self.model` using training set and measure perf using\n",
    "        training and validation set.\n",
    "\n",
    "        `debug`: if True, will run train_one_batch function with one batch\n",
    "        of train_dataloader to see if we can overfit the model, used to debug\n",
    "        the training loop.\n",
    "\n",
    "        `train_dataloader`: training set\n",
    "        `valid_dataloader`: validation set\n",
    "        \"\"\"\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        if debug:\n",
    "            self.train_one_batch()\n",
    "        else:\n",
    "            time_per_epoch = []\n",
    "            if self.ipx:\n",
    "                self._to_ipx()\n",
    "            print(f\"fine tuning model for max epochs: {self.epochs}\")\n",
    "            for epoch in range(self.epochs):\n",
    "                print(f\"Epoch: [{epoch+1}]\")\n",
    "                st_time = time.perf_counter()\n",
    "                t_epoch_loss, t_epoch_acc = self.train()\n",
    "                fn_time = time.perf_counter()\n",
    "                time_per_epoch.append(fn_time - st_time)\n",
    "                v_epoch_loss, v_epoch_acc = self.validate()\n",
    "                self.metrics.loss[\"train\"].append(t_epoch_loss / len(train_dataloader))\n",
    "                self.metrics.loss[\"val\"].append(v_epoch_loss / len(valid_dataloader))\n",
    "                self.metrics.acc[\"train\"].append(t_epoch_acc / len(train_dataloader))\n",
    "                self.metrics.acc[\"val\"].append(v_epoch_acc / len(valid_dataloader))\n",
    "                print(self.metrics)\n",
    "            return time_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a30e4e-1e97-4336-8162-6269d28ffd50",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd151fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DinosourBoneFinder()  # init model\n",
    "trainer = Trainer(model, epochs=6, ipx=True)  # set up trainer with the model\n",
    "tft = trainer.fine_tune(train_dataloader, valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48061a-649c-41d8-bec1-e14fd68d7a79",
   "metadata": {},
   "source": [
    "## Training / Validation loss and accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e460dd-49eb-42b7-a435-a1439cf9af24",
   "metadata": {},
   "source": [
    "## Save the model \n",
    "\n",
    "Save it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f49b8-a25d-481d-948e-05ef46628cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18_3Class_RN\"\n",
    "model_scripted = torch.jit.script(model)  # Export to TorchScript\n",
    "model_scripted.save(f\"models/{model_name}.pt\")  # Save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fdbef-93e8-4660-857a-6b4c2c6b132f",
   "metadata": {},
   "source": [
    "## Load a Saved Model\n",
    "\n",
    "Use this to load a previously created model to test if we were successfully able to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965f1e1-b04c-41d2-9441-1b5a0a3467f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18_3Class_RN\"\n",
    "model_read = torch.jit.load(f\"models/{model_name}.pt\")\n",
    "model_read.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cca1f5-7175-41f7-94ea-50c299176d81",
   "metadata": {},
   "source": [
    "## Infer Function\n",
    "\n",
    "Used to score and get associated filename for each scored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92ad1f-f331-4319-a42f-2483a8dc3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"custom ImageFolder to get the filepaths along with the image and label data.\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths = ((self.imgs[index][0]),)\n",
    "        return super().__getitem__(index) + paths\n",
    "\n",
    "\n",
    "def infer(model, data_path: str):\n",
    "    \"\"\"give trained `model` & `data_path` where images whose\n",
    "    labels have to be predicted are kept.\n",
    "\n",
    "    `data_path`: path to data eg. ./test/<random_class>/*.png\n",
    "    it's important to have a folder with a`random class` name as ImgFolder\n",
    "    expects it.\n",
    "\n",
    "    returns: (\n",
    "        images: images loaded from disk for inferece,\n",
    "        yhats: predicted labels\n",
    "        paths: image file-path on disk        )\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(*imagenet_stats)]\n",
    "    )\n",
    "    data = ImageFolderWithPaths(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    yhats = []\n",
    "    images = []\n",
    "    paths = []\n",
    "    for (imgs, _, fpaths) in dataloader:\n",
    "        yhat = model(imgs)\n",
    "        yhat = yhat.max(1)[1]\n",
    "        yhat = yhat.data.cpu().numpy()\n",
    "        yhats.extend(yhat)\n",
    "        paths.extend(fpaths)\n",
    "        images.extend(imgs.data.cpu())\n",
    "    return images, yhats, paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ad634-b1b5-456b-a47c-9a7b30de7ddb",
   "metadata": {},
   "source": [
    "## How to use the Infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228abb78-54e6-4231-b1f8-77826271f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/ThreeClassManualRemove0s/test\n",
    "!mkdir  data/ThreeClassManualRemove0s/test/unknown\n",
    "!cp data/DinosaurNationalMonument/20220514/224/*.jpg data/ThreeClassManualRemove0s/test/unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebabad9-84cb-4dfe-ac4f-b63b4e76739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "images, yhats, img_paths = infer(\n",
    "    model_read, data_path=\"./data/ThreeClassManualRemove0s/test/\"\n",
    ")\n",
    "infer_dataloader = DataLoader([*zip(images, yhats)], batch_size=100, shuffle=False)\n",
    "print(\"infered images with labels\")\n",
    "show_data(infer_dataloader, imagenet_stats, 10, figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2655e94-dd4a-4193-8ff5-09bf4df08a89",
   "metadata": {},
   "source": [
    "If you have any issues or want to contribute, please contact our authors:\n",
    "Intel oneAPI Solution Architect\n",
    "- Unnikrishnan Nair, Rahul [rahul.unnikrishnan.nair (at) intel.com]\n",
    "- Chesebrough, Bob [bob.chesebrough (at) intel.com]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585625a",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "1. What will happen to the accuracy curves & training time:\n",
    "    - if we use ResNet50 as the backbone instead of ResNet18?\n",
    "    - if another optimizer is used, for Eg. Instead of SGD, if we used Adam?\n",
    "2. Difference in time taken for training with ipex and without ipex?</br>\n",
    "    **Note**: To do this experiment, call the `fine_tune` method using `ipx=False`\n",
    "3. If we don't use the fine-tuning approach and use the same Resnet18 with pretraining turned off (`pretrain=False`), how many epochs do we have to train the model?\n",
    "4. If we don't `zero` the gradients in the training loop, what effect does it have on training?\n",
    "5. Can a custom CNN-based classifier be trained to classify our dataset more accurately than the approach we used here?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9665b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1733b34285ed74833bcb8e1b7a940727029b0435f34e09e572d05f37d583a466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
