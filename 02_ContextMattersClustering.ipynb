{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Context Matters - Clustering\n",
    "\n",
    "Lets begin by asserting that we have collected GPS location data fo various fossil samples. Many times a dinosaur bone fragment may be similiar in color, texture, and details to other fossils - So how can we gain confience that what we found was bone?\n",
    "\n",
    "\n",
    "## How to I know if what I have found is bone?\n",
    "\n",
    "There are look alike fossils and minerals that can be mistaken for bone:\n",
    "- PetrifiedWood\n",
    "- Selenite (Calcium Sulphate)\n",
    "- Calcite (Caclium Carbonete)\n",
    "- Crocodile Skutes and bones\n",
    "- Shark teeth\n",
    "\n",
    "1) Look at examples of dinosaur bone from a rock shop\n",
    "\n",
    "- Get to know what it feels like, what it looks like including fine grain and cellular structures\n",
    "2) Context matters\n",
    "- Is there documentation that proves other bones have been found nearby or in similar geological deposits?\n",
    "\n",
    "<img src=\"assets/GPS.jpg\" width=\"500\"/>\n",
    "\n",
    "\n",
    "# Dinosaur Bones Come in All Shapes, Sizes, Textures\n",
    "\n",
    "All bone will have similar structures as follows:\n",
    "\n",
    "<img src=\"assets/BoneStructure.jpg\" width=\"500\"/>\n",
    "\n",
    "# Macro Shots of Bone Stucture\n",
    "\n",
    "This is what bone looks like up close (photo credits to Ben Chesebrough)\n",
    "\n",
    "<img src=\"assets/BenChesebroughMacroBoneRedOrange.jpg\" width=\"500\"/>\n",
    "\n",
    "<img src=\"assets/BenChesebroughMacroBoneYellow.jpg\" width=\"500\"/>\n",
    "\n",
    "<img src=\"assets/BenChesebroughMacroBoneWhite.jpg\" width=\"500\"/>\n",
    "\n",
    "BenChesebroughMacroBoneYellow\n",
    "\n",
    "# But there is also a wide variety\n",
    "\n",
    "Many colors, textures, grain or pore sizes, conditions of the fossil, etc.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"assets/ZSC_7683AIbone.jpg\" width=\"500\"/>\n",
    "\n",
    "\n",
    "<img src=\"assets/DinosaurBonesLookLike.jpg\" width=\"500\"/>\n",
    "\n",
    "\n",
    "\n",
    "# Petrified Wood\n",
    "\n",
    "Petrified wood is often mistaken for dinosaur bone. It can have a similar long grain structure, but does not exhbit the osteon cell patterns found in bone.\n",
    "\n",
    "<img src=\"assets/PetrifiedWoodcropped1.jpg\" width=\"360\"/>\n",
    "\n",
    "<img src=\"assets/PetrifiedWoodcropped2.jpg\" width=\"360\"/>\n",
    "\n",
    "# Shark Teeth\n",
    "\n",
    "Shark teeth can be mistaken for dinosaur teeth. Many people find it hard ot believe that shark teeth are found at elevation of 7000 feet above sea level in the New MExico desert, and so they get misclassified as dinosaur teeth\n",
    "\n",
    "<img src=\"assets/SharkTeeth20220520_113552.jpg\" width=\"360\"/>\n",
    "\n",
    "# Crocodilian Skutes\n",
    "\n",
    "We have been tripped up by croocodile skutes on many occasions. The skutes are boney and can be very similar to dinosaur bone. The give away here is to look for the periodic dimples on the outer surface - this can indicate turtle or croccodile as the source.\n",
    "\n",
    "<img src=\"assets/CrocodilianSkutes20220520_112944.jpg\" width=\"360\"/>\n",
    "\n",
    "Lets put all of our GPS data into a spreadsheet and perform Unsupervised learning to begin to identify context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context matters!\n",
    "\n",
    "<img src=\"assets/NGMDB_DNM.jpg\" width=\"500\"/>\n",
    "\n",
    "\n",
    "Consult a **geologic map** to determine if the fossils you found are within a specified geological context - this will give you an idication of whether you found shark teeth in a marine environment or bones in a terrestrial environment. Or, it will indicate that the specimen you have is from the **Triassic, Jurassic, or Cretaceous periods** - these are the dinosaur periods. If geologists have already identified that your search area is a tertiary or quaternary time then what you found are NOT dinosaurs fossils.\n",
    "\n",
    "Once you find a cluster of fossils in close prximity, it is more likle that the other fossils nearby are from the same or simialr specimens or ate least from the same time period\n",
    "\n",
    "In some cases, we find thousands of samples of petrified wood and no bone.\n",
    "\n",
    "Other time we find hundreds of bones fragments, but no petrified wood.\n",
    "\n",
    "Same for shark teeth. Shark teeth areas TEND to exclude bone fragments from being dinosaur bones (but this is not a hard and fast rule)\n",
    "\n",
    "In some cases we find petrified wood and crocdilian skutes mingled together and then a few hundred yards away we find dinosaur bones grouped to gether.\n",
    "\n",
    "BUT - MANY, MANY times, finding a few defintitive bone samples help us conclude the very nearby samples are likely also bone same for shark teeth - find a few definitive ones and the partial fossils are most likley also shark teeth and so on.\n",
    "\n",
    "# Goal: Identify clusters\n",
    "\n",
    "What we would like is to plot our GPS coordinates and look for patterns suggesting that fossils which are clustering together.\n",
    "\n",
    "In some cases the clusters will overlap, but in many other cases, the clusters tend to reveal that fossil of simialr nature are found together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets import make_blobs\n",
    "n_components = 4\n",
    "\n",
    "labels = ['bone', 'shark teeth', 'crocodilian', 'petrified wood']\n",
    "\n",
    "X, truth = make_blobs(n_samples=3000, centers=n_components, \n",
    "                      cluster_std = [2, 1.5, 1, 1], \n",
    "                      random_state=42)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, c = truth, cmap='Set1')\n",
    "plt.title(f\"Map of a mixture of 300 fossils of {n_components} fossils types \")\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the real world, \n",
    "\n",
    "We typically cannot identify each fossil specifically\n",
    "- the fossil is too small (shape does not help)\n",
    "- the fossil is too similar to other types of fossils\n",
    "- too many species were buried in the same area\n",
    "\n",
    "## The point is: Our map typically looks like this \n",
    "\n",
    "Because we dont even know what kinds of fossils we actually have, our first step is to identify any naturally occuring clusters. Since we dont yet have any other information about the fossils - they are all colored the same - gray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], s=50, c = 'lightgray')\n",
    "plt.title(f\"Map of a mixture of 3000 fossils of {n_components} fossils types \")\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with KMeans \n",
    "\n",
    "For simple distributions like the one above, we might try to cluster via Kmeans.\n",
    "\n",
    "FYI: Applying the patch_sklearn() from the Intel Extensions for Scikit-learn* yirelds a speedup of 4 to 5X during the fitting of the model.\n",
    "\n",
    "## Exercise: Experiment with patching and unpatching \n",
    "\n",
    "You can patch or unpatch subsequent imports from sklearn. Just be sure to patch before you import from sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "print(f\"elapsed: {time.time() - start} seconds\")\n",
    "kmeans.labels_\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], s=50, c = kmeans.labels_)\n",
    "plt.title(f\"Map of a mixture of 300 fossils of {n_components} fossils types \")\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.grid()\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower right\", title=\"Classes\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()\n",
    "i =0\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "index = {}\n",
    "# create a dictionary to track indexes of each laebels class\n",
    "# identified by clustering\n",
    "for i in range(4):\n",
    "    index[i] = np.where(labels == i)\n",
    "    \n",
    "# there are 40 to 60 points in each cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context! \n",
    "\n",
    "Now identification has gotten easier\n",
    "\n",
    "Identify one or two of these samples as dinosaur bone and chances are good the rest of the pile are bones too!\n",
    "\n",
    "<img src=\"assets/BlackBones20150319_1315IMG_6255.jpg\" width=\"500\"/>\n",
    "\n",
    "We can take photographs, video, gps coordinates, measurements and head back for an interenet search to try to identify a even a small number of fossils from each cluster. We can choose the best specimens, or the most representative, or the ones with outer curved surfaces that may help identify the specimen\n",
    "\n",
    "<img src=\"assets/Claw snapped from goProVid.JPG\" width=\"500\"/>\n",
    "\n",
    "This claw belonging to an Allosaurus helped us identify other bones nearby as belonging to the same animal (probably).\n",
    "\n",
    "<img src=\"assets/StegosaurSpike.PNG\" width=\"500\"/>\n",
    "\n",
    "Similarly, this Stegosaurus spike, helped us identify nearby bones as likley belonging to Stegosaurus.\n",
    "\n",
    "<img src=\"assets/Camarasaurus tooth Z50_9217.jpg\" width=\"244\"/>\n",
    "\n",
    "Here, this Camarasurus tooth find, helped us identify otherwise unidentifiable limbs bones nearby.\n",
    "\n",
    "**Context** can help identify the other unkown fossils once we get a postive identification fo a few specimens.\n",
    "\n",
    "For a fun way to thinnk about geological context, I recommend the video *\"FROM THE EARTH TO THE MOON (1998): SEASON 1, EPISODE 10 - GALILEO WAS RIGHT\"*. This episode recounts the  Apollo 15 astronauts and backup crew go through extensive geology training in preparation for their mission.  Dr. Leon (Lee) Silver articulates the importance of context in a geological setting. Context is vital for identifying dinosaur bones as well.\n",
    "\n",
    "The problem with kmeans is that every time we run it - it may assign a different cluster ID to each point so sometime the blob at the lower left will be identified as cluster 2 and other runs it will be identified as cluster 3 for example\n",
    "\n",
    "So it has given us great insight and gotten us to a point where we might classify these points in a more consistnent way.\n",
    "\n",
    "# Classifier Will Color Sites Consistently\n",
    "\n",
    "## Exercise: Experiment with patching and unpatching SVC\n",
    "\n",
    "The Intel Extensions for Scikit-learn accelerate select functions in scikit-learn suchas kmeans, dbscan, pca, random forest, SVC, K neaest neighbor, and more.\n",
    "\n",
    "It is implemented via a patching contruct\n",
    "\n",
    "After installing Intel Extensions for Scikit-learn (not necesssay on Intel DevCloud), simply import and patch BEFORE you import your desired scikit-learn alogithms\n",
    "\n",
    "- from sklearnex import patch_sklearn\n",
    "- patch_sklearn()\n",
    "\n",
    "These two lines can accelerate commonly used ML algorithms enormously! See [link](https://github.com/intel/scikit-learn-intelex)  for more information including potentially acceleration.\n",
    "\n",
    "<img src=\"assets/scikit-learn-acceleration-2021.2.3.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use 8 points from each class to create a classifier\n",
    "# the classifier uses 8 values of X and 8 values of y for each class \n",
    "# to fit a classifier model to the data\n",
    "# then we can use the classifier to predict \n",
    "# a bone type based on locality of the find\n",
    "from sklearnex import patch_sklearn\n",
    "unpatch_sklearn()\n",
    "\n",
    "X_train = X[index[0][0][:80]]\n",
    "X_train =  np.append(X_train, X[index[1][0][:8]], axis = 0)\n",
    "X_train =  np.append(X_train, X[index[2][0][:8]], axis = 0)\n",
    "X_train =  np.append(X_train, X[index[3][0][:8]], axis = 0)\n",
    "\n",
    "y_train = labels[index[0][0][:80]]\n",
    "y_train =  np.append(y_train, labels[index[1][0][:8]], axis = 0)\n",
    "y_train =  np.append(y_train, labels[index[2][0][:8]], axis = 0)\n",
    "y_train =  np.append(y_train, labels[index[3][0][:8]], axis = 0)\n",
    "\n",
    "patch_sklearn(\"SVC\") # patch SVC algo \n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC  # accelerated with Intel Extensions for Scikit-learn\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "start = time.time()\n",
    "clf.fit(X_train,  y_train.ravel())\n",
    "y_pred = clf.predict(X)\n",
    "print(f\"{time.time() - start} seconds\")\n",
    "plt.scatter(X[:,0], X[:,1], c = y_pred)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with DBSCAN for more complicated data distributions\n",
    "\n",
    "We will use DBSCAN from scikit-learn to attemp to identify our clustering.\n",
    "\n",
    "BUT - DBSCAN requires a parameter called EPS - which is the minimum distance bewteen points to be considered part of the same cluster\n",
    "\n",
    "To find a good value for EPS - we will use sscikit-learn's nearest neighbor to plot the all the paris fo distances to help identify a good starting value to use for DBSCAN\n",
    "\n",
    "We plot a sorted distance curve and look for the distance that best represents a knee or sometimes the large values from the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "patch_sklearn() # patch all remaining sklearn imports\n",
    "nn = NearestNeighbors(n_neighbors=2).fit(X)\n",
    "\n",
    "distances, indices = nn.kneighbors(X)\n",
    "plt.plot(sorted(distances[:,1]))\n",
    "plt.ylabel('Distance')\n",
    "plt.xlabel('Number of finds')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee = .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sklearn()\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "start = time.time()\n",
    "\n",
    "clustering = DBSCAN(eps = 1.4, min_samples = 5 ).fit(X)\n",
    "print(f\"{time.time() - start} seconds\")\n",
    "\n",
    "color = clustering.labels_\n",
    "\n",
    "labels = [str(i) for i in np.unique(clustering.labels_).tolist()]\n",
    "plt.legend(labels)\n",
    "scatter = plt.scatter(X[:,0], X[:,1], c = color)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower right\", title=\"Classes\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: DBSCAN Identifies Outliers as class -1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel density Estimation\n",
    "\n",
    "single long vector\n",
    "\n",
    "have to reshape \n",
    "\n",
    "say that often when you get home you drop your keys and relax for dinner. Later you decide to drive to a grocery store for snacks. You've lost your keys!\n",
    "\n",
    "But you have lost your keys many times before and have kep a reocrd of exactly where you found them over the course of time\n",
    "\n",
    "It seems reasonable that the likely that finding your keys near to locations you found them previously is high. Finding them in your dining room, living room, bathroom, bedroom each have historical probabilites.\n",
    "\n",
    "On the other hand, seeing as you've never been to Nome Alaska, your likelyhood of finding your keys there is very nearly zero.\n",
    "\n",
    "Even if you have never found your keys in the bathroom before, it makes sense that the probability of finding keys in the bathroom is higher than finding your keys in Nome.  There is a sense in which the density of finds and nearby locations have higher probablities than locations very, very far away.\n",
    "\n",
    "This is similar to finding dinosaur bones, petrified wood, prehistoric shark teeth, prehistoric crocodilian remains.  The probability of finding a dinosaur bone is higher when other dinosaur bones have been found nearby\n",
    "\n",
    "This is where clustering and kernel density estimation can help to determine what a given sample of likely to be and how likely it is to find a bone in a particular location \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract x and y\n",
    "x = X[:, 0]  # n_smaples is number of bone locations\n",
    "y = X[:, 1]\n",
    "# Define the borders\n",
    "deltaX = (max(x) - min(x))/10\n",
    "deltaY = (max(y) - min(y))/10\n",
    "xmin = min(x) - deltaX\n",
    "xmax = max(x) + deltaX\n",
    "ymin = min(y) - deltaY\n",
    "ymax = max(y) + deltaY\n",
    "print(xmin, xmax, ymin, ymax)\n",
    "# Create meshgrid\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()]) # stack into 1D for KDE calc\n",
    "values = np.vstack([x, y])\n",
    "kernel = st.gaussian_kde(values)\n",
    "f = np.reshape(kernel(positions).T, xx.shape) # reshape to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.gca()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "cfset = ax.contourf(xx, yy, f, cmap='coolwarm')\n",
    "ax.imshow(np.rot90(f), cmap='coolwarm', extent=[xmin, xmax, ymin, ymax])\n",
    "cset = ax.contour(xx, yy, f, colors='k')\n",
    "ax.clabel(cset, inline=1, fontsize=10)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.title('2D Gaussian Kernel density estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = f > .006\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "# ax = fig.gca()\n",
    "# ax.set_xlim(xmin, xmax)\n",
    "# ax.set_ylim(ymin, ymax)\n",
    "# ax.scatter(xx[idx], yy[idx])\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.integrate import simps\n",
    "# import numpy as np\n",
    "\n",
    "# # x = np.linspace(0, 1, 20)                # x.shape  (20,)\n",
    "# # y = np.linspace(0, 1, 30)                # y.shape  (30,)\n",
    "# # z = np.cos(x[:,None])**4 + np.sin(y)**2  #z.shape (20, 30)\n",
    "# # simps(simps(f, yy[0,:]), xx[:,0])\n",
    "\n",
    "# # -11.097585529030251 9.858180523990058 -11.545696279950441 16.81828998331647\n",
    "# simps(simps(f, yy[0,:]), xx[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the highest peak\n",
    "\n",
    "Probability of 1 at the max location - like 100% chance Mammoth Mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fNorm = f/f.max()\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.gca()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "cfset = ax.contourf(xx, yy, fNorm, cmap='coolwarm')\n",
    "ax.imshow(np.rot90(f), cmap='coolwarm', extent=[xmin, xmax, ymin, ymax])\n",
    "cset = ax.contour(xx, yy, fNorm, colors='k')\n",
    "ax.clabel(cset, inline=1, fontsize=10)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.title('2D Gaussian Kernel density estimation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (IntelÂ® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
